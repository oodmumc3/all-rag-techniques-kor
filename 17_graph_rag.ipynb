{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 그래프 RAG: 그래프 강화 검색 증강 생성\n",
    "\n",
    "이 노트북에서는 지식을 평평한 문서 모음이 아닌 연결된 그래프로 구성하여 기존 RAG 시스템을 향상시키는 기술인 그래프 RAG(Graph RAG)를 구현합니다. 이를 통해 시스템은 관련 개념을 탐색하고 표준 벡터 유사성 접근 방식보다 문맥적으로 더 관련성 높은 정보를 검색할 수 있습니다.\n",
    "그래프 RAG는 문서 내의 정보를 단순히 텍스트 조각으로 나누는 것을 넘어, 정보 조각들 간의 관계를 파악하여 그래프 형태로 표현합니다. 각 정보 조각은 그래프의 노드(node)가 되고, 정보 간의 관계는 엣지(edge)로 표현됩니다. 사용자의 질문이 들어오면, 질문과 관련된 노드를 찾고, 그 노드와 연결된 다른 노드들을 탐색하여 답변 생성에 필요한 풍부한 문맥 정보를 수집합니다. 이는 복잡한 질문이나 여러 정보 조각을 종합해야 하는 질문에 대해 더 효과적인 답변을 생성하는 데 도움이 됩니다.\n",
    "\n",
    "그래프 RAG의 주요 이점\n",
    "\n",
    "- 정보 조각 간의 관계를 보존합니다.\n",
    "- 연결된 개념을 통해 탐색하여 관련 컨텍스트를 찾을 수 있습니다.\n",
    "- 복잡하고 여러 부분으로 구성된 질의 처리를 개선합니다.\n",
    "- 시각화된 지식 경로를 통해 더 나은 설명 가능성을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "필요한 라이브러리를 가져오는 것으로 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Tuple, Any # 타입 힌팅용\n",
    "import networkx as nx # 그래프 생성 및 조작용\n",
    "import matplotlib.pyplot as plt # 그래프 시각화용\n",
    "import heapq # 우선순위 큐 (그래프 탐색용)\n",
    "from collections import defaultdict # 기본값 딕셔너리용\n",
    "import re\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API 클라이언트 설정\n",
    "임베딩과 응답을 생성하기 위해 OpenAI 클라이언트를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 URL과 API 키로 OpenAI 클라이언트 초기화\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 환경 변수에서 API 키 검색\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트 내용을 추출합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        \n",
    "    Returns:\n",
    "        str: 추출된 텍스트 내용\n",
    "    \"\"\"\n",
    "    print(f\"{pdf_path}에서 텍스트 추출 중...\")  # 처리 중인 PDF 경로 출력\n",
    "    pdf_document = fitz.open(pdf_path)  # PyMuPDF를 사용하여 PDF 파일 열기\n",
    "    text_content = \"\"  # 추출된 텍스트를 저장할 빈 문자열 초기화 (text를 text_content로 변경)\n",
    "    \n",
    "    # PDF의 각 페이지 반복\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]  # 페이지 객체 가져오기\n",
    "        text_content += page.get_text()  # 페이지에서 텍스트 추출하여 문자열에 추가\n",
    "    \n",
    "    return text_content  # 추출된 텍스트 내용 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 중첩되는 청크로 분할합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 청킹할 입력 텍스트\n",
    "        chunk_size (int): 각 청크의 문자 크기\n",
    "        overlap (int): 청크 간 문자 중첩\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 메타데이터를 포함하는 청크 목록\n",
    "    \"\"\"\n",
    "    chunks_list = []  # 청크를 저장할 빈 리스트 초기화 (chunks를 chunks_list로 변경)\n",
    "    \n",
    "    # (chunk_size - overlap) 크기의 단계로 텍스트 반복\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        # 현재 위치에서 텍스트 청크 추출\n",
    "        chunk_text_content = text[i:i + chunk_size] # chunk_text를 chunk_text_content로 변경\n",
    "        \n",
    "        # 빈 청크를 추가하지 않도록 확인\n",
    "        if chunk_text_content:\n",
    "            # 메타데이터와 함께 청크를 리스트에 추가\n",
    "            chunks_list.append({\n",
    "                \"text\": chunk_text_content,  # 텍스트 청크\n",
    "                \"index\": len(chunks_list),  # 청크의 인덱스\n",
    "                \"start_pos\": i,  # 원본 텍스트에서 청크의 시작 위치\n",
    "                \"end_pos\": i + len(chunk_text_content)  # 원본 텍스트에서 청크의 끝 위치\n",
    "            })\n",
    "    \n",
    "    # 생성된 청크 수 출력\n",
    "    print(f\"생성된 텍스트 청크 수: {len(chunks_list)}\")\n",
    "    \n",
    "    return chunks_list  # 청크 목록 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에 대한 임베딩을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): 입력 텍스트 목록\n",
    "        model (str): 임베딩 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: 임베딩 벡터 목록\n",
    "    \"\"\"\n",
    "    # 빈 입력 처리\n",
    "    if not texts:\n",
    "        return []\n",
    "        \n",
    "    # 필요한 경우 배치로 처리 (OpenAI API 제한)\n",
    "    batch_size = 100\n",
    "    all_embeddings_list = [] # all_embeddings를 all_embeddings_list로 변경\n",
    "    \n",
    "    # 입력 텍스트를 배치로 반복\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]  # 현재 텍스트 배치 가져오기 (batch를 batch_texts로 변경)\n",
    "        \n",
    "        # 현재 배치에 대한 임베딩 생성\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch_texts\n",
    "        )\n",
    "        \n",
    "        # 응답에서 임베딩 추출\n",
    "        batch_embeddings_list = [item.embedding for item in response.data] # batch_embeddings를 batch_embeddings_list로 변경\n",
    "        all_embeddings_list.extend(batch_embeddings_list)  # 배치 임베딩을 리스트에 추가\n",
    "    \n",
    "    return all_embeddings_list  # 모든 임베딩 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지식 그래프 구축\n",
    "텍스트 청크에서 주요 개념을 추출하고, 공유된 개념을 기반으로 노드(청크)들을 연결하여 지식 그래프를 만듭니다. 노드 간의 엣지 가중치는 개념 공유 정도와 의미론적 유사도를 조합하여 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_concepts(text):\n",
    "    \"\"\"\n",
    "    OpenAI의 API를 사용하여 텍스트에서 주요 개념을 추출합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 개념을 추출할 텍스트\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: 개념 목록\n",
    "    \"\"\"\n",
    "    # 모델에 수행할 작업을 지시하는 시스템 메시지\n",
    "    system_message = \"\"\"제공된 텍스트에서 주요 개념과 엔티티를 추출하십시오.\n",
    "이 텍스트에서 가장 중요한 5-10개의 주요 용어, 엔티티 또는 개념 목록만 반환하십시오.\n",
    "응답 형식을 문자열의 JSON 배열로 지정하십시오.\"\"\"\n",
    "\n",
    "    # OpenAI API에 요청 만들기\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"다음에서 주요 개념을 추출하십시오:\\n\\n{text[:3000]}\"}  # API 제한을 위해 텍스트 자르기\n",
    "        ],\n",
    "        temperature=0.0, # 결정론적 출력을 위해 온도 0 설정\n",
    "        response_format={\"type\": \"json_object\"} # JSON 객체 형식으로 응답 요청\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # 응답에서 개념 파싱\n",
    "        concepts_data = json.loads(response.choices[0].message.content) # concepts_json을 concepts_data로 변경\n",
    "        extracted_concepts = concepts_data.get(\"concepts\", []) # concepts를 extracted_concepts로 변경\n",
    "        if not extracted_concepts and \"concepts\" not in concepts_data:\n",
    "            # 응답에서 모든 배열을 가져오려고 시도\n",
    "            for key, value in concepts_data.items():\n",
    "                if isinstance(value, list):\n",
    "                    extracted_concepts = value\n",
    "                    break\n",
    "        return extracted_concepts\n",
    "    except (json.JSONDecodeError, AttributeError):\n",
    "        # JSON 파싱 실패 시 대체 처리\n",
    "        content_text = response.choices[0].message.content # content를 content_text로 변경\n",
    "        # 리스트처럼 보이는 모든 항목 추출 시도\n",
    "        matches = re.findall(r'\\[(.*?)\\]', content_text, re.DOTALL)\n",
    "        if matches:\n",
    "            items_list = re.findall(r'\"([^\"]*)\"', matches[0]) # items를 items_list로 변경\n",
    "            return items_list\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knowledge_graph(chunks):\n",
    "    \"\"\"\n",
    "    텍스트 청크에서 지식 그래프를 구축합니다.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[Dict]): 메타데이터를 포함하는 텍스트 청크 목록\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[nx.Graph, List[np.ndarray]]: 지식 그래프 및 청크 임베딩\n",
    "    \"\"\"\n",
    "    print(\"지식 그래프 구축 중...\")\n",
    "    \n",
    "    # 그래프 생성\n",
    "    graph_obj = nx.Graph() # graph를 graph_obj로 변경\n",
    "    \n",
    "    # 청크 텍스트 추출\n",
    "    texts_list = [chunk_item[\"text\"] for chunk_item in chunks] # texts를 texts_list로, chunk를 chunk_item으로 변경\n",
    "    \n",
    "    # 모든 청크에 대한 임베딩 생성\n",
    "    print(\"청크에 대한 임베딩 생성 중...\")\n",
    "    chunk_embeddings = create_embeddings(texts_list) # embeddings를 chunk_embeddings로 변경\n",
    "    \n",
    "    # 그래프에 노드 추가\n",
    "    print(\"그래프에 노드 추가 중...\")\n",
    "    for i, chunk_item in enumerate(chunks):\n",
    "        # 청크에서 개념 추출\n",
    "        print(f\"청크 {i+1}/{len(chunks)}에 대한 개념 추출 중...\")\n",
    "        extracted_concepts = extract_concepts(chunk_item[\"text\"]) # concepts를 extracted_concepts로 변경\n",
    "        \n",
    "        # 속성과 함께 노드 추가\n",
    "        graph_obj.add_node(i, \n",
    "                      text=chunk_item[\"text\"], \n",
    "                      concepts=extracted_concepts,\n",
    "                      embedding=chunk_embeddings[i])\n",
    "    \n",
    "    # 공유된 개념을 기반으로 노드 간 연결 생성\n",
    "    print(\"노드 간 엣지 생성 중...\")\n",
    "    for i in range(len(chunks)):\n",
    "        node_concepts_set = set(graph_obj.nodes[i][\"concepts\"]) # node_concepts를 node_concepts_set으로 변경\n",
    "        \n",
    "        for j in range(i + 1, len(chunks)):\n",
    "            # 개념 중첩 계산\n",
    "            other_node_concepts = set(graph_obj.nodes[j][\"concepts\"]) # other_concepts를 other_node_concepts로 변경\n",
    "            shared_node_concepts = node_concepts_set.intersection(other_node_concepts) # shared_concepts를 shared_node_concepts로 변경\n",
    "            \n",
    "            # 개념을 공유하면 엣지 추가\n",
    "            if shared_node_concepts:\n",
    "                # 임베딩을 사용하여 의미론적 유사도 계산\n",
    "                similarity_score = np.dot(chunk_embeddings[i], chunk_embeddings[j]) / (np.linalg.norm(chunk_embeddings[i]) * np.linalg.norm(chunk_embeddings[j])) # similarity를 similarity_score로 변경\n",
    "                \n",
    "                # 개념 중첩과 의미론적 유사도를 기반으로 엣지 가중치 계산\n",
    "                # 두 노드 중 개념 수가 적은 쪽을 기준으로 중첩 비율 계산 (분모 0 방지)\n",
    "                min_concepts_len = min(len(node_concepts_set), len(other_node_concepts)) \n",
    "                concept_overlap_score = len(shared_node_concepts) / min_concepts_len if min_concepts_len > 0 else 0 # concept_score를 concept_overlap_score로 변경\n",
    "                edge_weight_value = 0.7 * similarity_score + 0.3 * concept_overlap_score # edge_weight를 edge_weight_value로 변경\n",
    "                \n",
    "                # 중요한 관계가 있는 엣지만 추가 (예: 가중치 0.6 초과)\n",
    "                if edge_weight_value > 0.6:\n",
    "                    graph_obj.add_edge(i, j, \n",
    "                                  weight=edge_weight_value,\n",
    "                                  similarity=similarity_score,\n",
    "                                  shared_concepts=list(shared_node_concepts))\n",
    "    \n",
    "    print(f\"{graph_obj.number_of_nodes()}개의 노드와 {graph_obj.number_of_edges()}개의 엣지로 지식 그래프 구축됨\")\n",
    "    return graph_obj, chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 탐색 및 질의 처리\n",
    "질의와 관련된 정보를 찾기 위해 지식 그래프를 탐색합니다. 질의와 유사한 노드에서 시작하여 연결된 노드들을 따라가며 관련 정보를 수집합니다. 우선순위 큐를 사용하여 관련성이 높은 노드를 먼저 탐색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_graph(query, graph, embeddings, top_k=5, max_depth=3):\n",
    "    \"\"\"\n",
    "    질의에 대한 관련 정보를 찾기 위해 지식 그래프를 탐색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        graph (nx.Graph): 지식 그래프\n",
    "        embeddings (List): 노드 임베딩 목록\n",
    "        top_k (int): 고려할 초기 노드 수\n",
    "        max_depth (int): 최대 탐색 깊이\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 그래프 탐색에서 얻은 관련 정보\n",
    "    \"\"\"\n",
    "    print(f\"'{query}' 질의에 대한 그래프 탐색 중...\")\n",
    "    \n",
    "    # 질의 임베딩 가져오기\n",
    "    query_embedding_vector = create_embeddings(query) # query_embedding을 query_embedding_vector로 변경\n",
    "    \n",
    "    # 모든 노드와 질의 간의 유사도 계산\n",
    "    node_similarities = [] # similarities를 node_similarities로 변경\n",
    "    for i, node_embedding_vector in enumerate(embeddings): # node_embedding을 node_embedding_vector로 변경\n",
    "        similarity_score = np.dot(query_embedding_vector, node_embedding_vector) / (np.linalg.norm(query_embedding_vector) * np.linalg.norm(node_embedding_vector)) # similarity를 similarity_score로 변경\n",
    "        node_similarities.append((i, similarity_score))\n",
    "    \n",
    "    # 유사도 기준으로 정렬 (내림차순)\n",
    "    node_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 시작점으로 상위 k개의 가장 유사한 노드 가져오기\n",
    "    initial_nodes = [node_idx for node_idx, _ in node_similarities[:top_k]] # starting_nodes를 initial_nodes로, node를 node_idx로 변경\n",
    "    print(f\"{len(initial_nodes)}개의 노드에서 탐색 시작\")\n",
    "    \n",
    "    # 탐색 초기화\n",
    "    visited_nodes = set()  # 방문한 노드를 추적하기 위한 집합 (visited를 visited_nodes로 변경)\n",
    "    path_of_traversal = []  # 탐색 경로를 저장할 리스트 (traversal_path를 path_of_traversal로 변경)\n",
    "    retrieved_results = []  # 결과를 저장할 리스트 (results를 retrieved_results로 변경)\n",
    "    \n",
    "    # 탐색을 위한 우선순위 큐 사용 (힙큐)\n",
    "    priority_queue = [] # queue를 priority_queue로 변경\n",
    "    for node_idx in initial_nodes:\n",
    "        heapq.heappush(priority_queue, (-node_similarities[node_idx][1], node_idx))  # 최대 힙을 위해 음수 사용\n",
    "    \n",
    "    # 우선순위를 사용한 수정된 너비 우선 탐색을 사용하여 그래프 탐색\n",
    "    while priority_queue and len(retrieved_results) < (top_k * 3):  # 결과를 top_k * 3으로 제한\n",
    "        _, current_node = heapq.heappop(priority_queue) # node를 current_node로 변경\n",
    "        \n",
    "        if current_node in visited_nodes:\n",
    "            continue\n",
    "        \n",
    "        # 방문한 것으로 표시\n",
    "        visited_nodes.add(current_node)\n",
    "        path_of_traversal.append(current_node)\n",
    "        \n",
    "        # 현재 노드의 텍스트를 결과에 추가\n",
    "        retrieved_results.append({\n",
    "            \"text\": graph.nodes[current_node][\"text\"],\n",
    "            \"concepts\": graph.nodes[current_node][\"concepts\"],\n",
    "            \"node_id\": current_node\n",
    "        })\n",
    "        \n",
    "        # 최대 깊이에 도달하지 않았으면 이웃 탐색\n",
    "        if len(path_of_traversal) < max_depth:\n",
    "            node_neighbors = [(neighbor_node, graph[current_node][neighbor_node][\"weight\"]) # neighbors를 node_neighbors로, neighbor를 neighbor_node로 변경\n",
    "                        for neighbor_node in graph.neighbors(current_node)\n",
    "                        if neighbor_node not in visited_nodes]\n",
    "            \n",
    "            # 엣지 가중치를 기준으로 이웃을 큐에 추가\n",
    "            for neighbor_node, edge_weight in sorted(node_neighbors, key=lambda x: x[1], reverse=True):\n",
    "                heapq.heappush(priority_queue, (-edge_weight, neighbor_node))\n",
    "    \n",
    "    print(f\"그래프 탐색 결과 {len(retrieved_results)}개의 관련 청크 찾음\")\n",
    "    return retrieved_results, path_of_traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 응답 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context_chunks):\n",
    "    \"\"\"\n",
    "    검색된 컨텍스트를 사용하여 응답을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        context_chunks (List[Dict]): 그래프 탐색에서 얻은 관련 청크\n",
    "        \n",
    "    Returns:\n",
    "        str: 생성된 응답\n",
    "    \"\"\"\n",
    "    # 컨텍스트의 각 청크에서 텍스트 추출\n",
    "    context_texts_list = [chunk_item[\"text\"] for chunk_item in context_chunks] # context_texts를 context_texts_list로, chunk를 chunk_item으로 변경\n",
    "    \n",
    "    # 추출된 텍스트를 \"---\"로 구분하여 단일 컨텍스트 문자열로 결합\n",
    "    combined_context_text = \"\\n\\n---\\n\\n\".join(context_texts_list) # combined_context를 combined_context_text로 변경\n",
    "    \n",
    "    # 컨텍스트의 최대 허용 길이 정의 (OpenAI 제한)\n",
    "    max_context_len = 14000 # max_context를 max_context_len으로 변경\n",
    "    \n",
    "    # 결합된 컨텍스트가 최대 길이를 초과하면 자르기\n",
    "    if len(combined_context_text) > max_context_len:\n",
    "        combined_context_text = combined_context_text[:max_context_len] + \"... [잘림]\"\n",
    "    \n",
    "    # AI 어시스턴트를 안내하는 시스템 메시지 정의\n",
    "    system_message_text = \"\"\"당신은 제공된 컨텍스트를 기반으로 질문에 답변하는 도움이 되는 어시스턴트입니다.\n",
    "    컨텍스트는 사용자의 질의와 관련하여 검색된 문서 세그먼트로 구성됩니다.\n",
    "    이러한 세그먼트의 정보를 사용하여 포괄적이고 정확한 답변을 제공하십시오.\n",
    "    컨텍스트에 질문에 답변할 관련 정보가 포함되어 있지 않으면 명확하게 그렇게 말하십시오.\"\"\" # system_message를 system_message_text로 변경\n",
    "\n",
    "    # OpenAI API를 사용하여 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 사용할 모델 지정\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message_text},  # 어시스턴트를 안내하는 시스템 메시지\n",
    "            {\"role\": \"user\", \"content\": f\"컨텍스트:\\n{combined_context_text}\\n\\n질문: {query}\"}  # 컨텍스트와 질의가 포함된 사용자 메시지\n",
    "        ],\n",
    "        temperature=0.2  # 응답 생성 온도 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 응답 내용 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph_traversal(graph, traversal_path):\n",
    "    \"\"\"\n",
    "    지식 그래프와 탐색 경로를 시각화합니다.\n",
    "    \n",
    "    Args:\n",
    "        graph (nx.Graph): 지식 그래프\n",
    "        traversal_path (List): 탐색 순서대로의 노드 목록\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))  # 그림 크기 설정\n",
    "    \n",
    "    # 노드 색상 정의, 기본값은 하늘색\n",
    "    node_colors_list = ['lightblue'] * graph.number_of_nodes() # node_color를 node_colors_list로 변경\n",
    "    \n",
    "    # 탐색 경로 노드를 연두색으로 강조 표시\n",
    "    for node_id in traversal_path: # node를 node_id로 변경\n",
    "        node_colors_list[node_id] = 'lightgreen'\n",
    "    \n",
    "    # 시작 노드를 녹색으로, 끝 노드를 빨간색으로 강조 표시\n",
    "    if traversal_path:\n",
    "        node_colors_list[traversal_path[0]] = 'green'\n",
    "        node_colors_list[traversal_path[-1]] = 'red'\n",
    "    \n",
    "    # 스프링 레이아웃을 사용하여 모든 노드의 위치 생성\n",
    "    positions = nx.spring_layout(graph, k=0.5, iterations=50, seed=42) # pos를 positions로 변경\n",
    "    \n",
    "    # 그래프 노드 그리기\n",
    "    nx.draw_networkx_nodes(graph, positions, node_color=node_colors_list, node_size=500, alpha=0.8)\n",
    "    \n",
    "    # 가중치에 비례하는 너비로 엣지 그리기\n",
    "    for u_node, v_node, edge_data in graph.edges(data=True): # u,v,data를 u_node, v_node, edge_data로 변경\n",
    "        edge_weight_val = edge_data.get('weight', 1.0) # weight를 edge_weight_val로 변경\n",
    "        nx.draw_networkx_edges(graph, positions, edgelist=[(u_node, v_node)], width=edge_weight_val*2, alpha=0.6)\n",
    "    \n",
    "    # 빨간색 점선으로 탐색 경로 그리기\n",
    "    traversal_edges_list = [(traversal_path[i], traversal_path[i+1]) # traversal_edges를 traversal_edges_list로 변경\n",
    "                      for i in range(len(traversal_path)-1)]\n",
    "    \n",
    "    nx.draw_networkx_edges(graph, positions, edgelist=traversal_edges_list, \n",
    "                          width=3, alpha=0.8, edge_color='red', \n",
    "                          style='dashed', arrows=True)\n",
    "    \n",
    "    # 각 노드에 대한 첫 번째 개념으로 레이블 추가\n",
    "    node_labels = {} # labels를 node_labels로 변경\n",
    "    for node_id in graph.nodes(): # node를 node_id로 변경\n",
    "        node_concepts = graph.nodes[node_id]['concepts'] # concepts를 node_concepts로 변경\n",
    "        label_text = node_concepts[0] if node_concepts else f\"노드 {node_id}\" # label을 label_text로 변경\n",
    "        node_labels[node_id] = f\"{node_id}: {label_text}\"\n",
    "    \n",
    "    nx.draw_networkx_labels(graph, positions, labels=node_labels, font_size=8)\n",
    "    \n",
    "    plt.title(\"탐색 경로가 있는 지식 그래프\")  # 플롯 제목 설정\n",
    "    plt.axis('off')  # 축 끄기\n",
    "    plt.tight_layout()  # 레이아웃 조정\n",
    "    plt.show()  # 플롯 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 그래프 RAG 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_rag_pipeline(pdf_path, query, chunk_size=1000, chunk_overlap=200, top_k=3):\n",
    "    \"\"\"\n",
    "    문서에서 답변까지 전체 그래프 RAG 파이프라인입니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 문서 경로\n",
    "        query (str): 사용자 질문\n",
    "        chunk_size (int): 텍스트 청크 크기\n",
    "        chunk_overlap (int): 청크 간 중첩\n",
    "        top_k (int): 탐색을 위해 고려할 상위 노드 수\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 답변 및 그래프 시각화 데이터를 포함하는 결과\n",
    "    \"\"\"\n",
    "    # PDF 문서에서 텍스트 추출\n",
    "    text_content = extract_text_from_pdf(pdf_path) # text를 text_content로 변경\n",
    "    \n",
    "    # 추출된 텍스트를 중첩되는 청크로 분할\n",
    "    document_chunks = chunk_text(text_content, chunk_size, chunk_overlap) # chunks를 document_chunks로 변경\n",
    "    \n",
    "    # 텍스트 청크에서 지식 그래프 구축\n",
    "    knowledge_graph, chunk_embeddings = build_knowledge_graph(document_chunks) # graph, embeddings 변수명 변경\n",
    "    \n",
    "    # 질의에 대한 관련 정보를 찾기 위해 지식 그래프 탐색\n",
    "    relevant_document_chunks, path_of_traversal = traverse_graph(query, knowledge_graph, chunk_embeddings, top_k) # relevant_chunks, traversal_path 변수명 변경\n",
    "    \n",
    "    # 질의와 관련 청크를 기반으로 응답 생성\n",
    "    response_text = generate_response(query, relevant_document_chunks) # response를 response_text로 변경\n",
    "    \n",
    "    # 그래프 탐색 경로 시각화\n",
    "    visualize_graph_traversal(knowledge_graph, path_of_traversal)\n",
    "    \n",
    "    # 질의, 응답, 관련 청크, 탐색 경로 및 그래프 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response_text,\n",
    "        \"relevant_chunks\": relevant_document_chunks,\n",
    "        \"traversal_path\": path_of_traversal,\n",
    "        \"graph\": knowledge_graph\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_rag(pdf_path, test_queries, reference_answers=None):\n",
    "    \"\"\"\n",
    "    여러 테스트 질의에 대해 그래프 RAG를 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 문서 경로\n",
    "        test_queries (List[str]): 테스트 질의 목록\n",
    "        reference_answers (List[str], optional): 비교를 위한 참조 답변\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 평가 결과\n",
    "    \"\"\"\n",
    "    # PDF에서 텍스트 추출\n",
    "    text_content = extract_text_from_pdf(pdf_path) # text를 text_content로 변경\n",
    "    \n",
    "    # 텍스트를 청크로 분할\n",
    "    document_chunks = chunk_text(text_content) # chunks를 document_chunks로 변경\n",
    "    \n",
    "    # 지식 그래프 구축 (모든 질의에 대해 한 번만 수행)\n",
    "    knowledge_graph, chunk_embeddings = build_knowledge_graph(document_chunks) # graph, embeddings 변수명 변경\n",
    "    \n",
    "    evaluation_results_list = [] # results를 evaluation_results_list로 변경\n",
    "    \n",
    "    for i, query_text in enumerate(test_queries): # query를 query_text로 변경\n",
    "        print(f\"\\n\\n=== 질의 {i+1}/{len(test_queries)} 평가 중 ===\")\n",
    "        print(f\"질의: {query_text}\")\n",
    "        \n",
    "        # 관련 정보를 찾기 위해 그래프 탐색\n",
    "        relevant_document_chunks, path_of_traversal = traverse_graph(query_text, knowledge_graph, chunk_embeddings) # relevant_chunks, traversal_path 변수명 변경\n",
    "        \n",
    "        # 응답 생성\n",
    "        response_text = generate_response(query_text, relevant_document_chunks) # response를 response_text로 변경\n",
    "        \n",
    "        # 사용 가능한 경우 참조 답변과 비교\n",
    "        reference_text = None # reference를 reference_text로 변경\n",
    "        comparison_analysis = None # comparison을 comparison_analysis로 변경\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference_text = reference_answers[i]\n",
    "            comparison_analysis = compare_with_reference(response_text, reference_text, query_text)\n",
    "        \n",
    "        # 현재 질의에 대한 결과 추가\n",
    "        evaluation_results_list.append({\n",
    "            \"query\": query_text,\n",
    "            \"response\": response_text,\n",
    "            \"reference_answer\": reference_text,\n",
    "            \"comparison\": comparison_analysis,\n",
    "            \"traversal_path_length\": len(path_of_traversal),\n",
    "            \"relevant_chunks_count\": len(relevant_document_chunks)\n",
    "        })\n",
    "        \n",
    "        # 결과 표시\n",
    "        print(f\"\\n응답: {response_text}\\n\")\n",
    "        if comparison_analysis:\n",
    "            print(f\"비교: {comparison_analysis}\\n\")\n",
    "    \n",
    "    # 평가 결과 및 그래프 통계 반환\n",
    "    return {\n",
    "        \"results\": evaluation_results_list,\n",
    "        \"graph_stats\": {\n",
    "            \"nodes\": knowledge_graph.number_of_nodes(),\n",
    "            \"edges\": knowledge_graph.number_of_edges(),\n",
    "            \"avg_degree\": sum(dict(knowledge_graph.degree()).values()) / knowledge_graph.number_of_nodes() if knowledge_graph.number_of_nodes() > 0 else 0 # 0으로 나누기 방지\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_reference(response, reference, query):\n",
    "    \"\"\"\n",
    "    생성된 응답을 참조 답변과 비교합니다.\n",
    "    \n",
    "    Args:\n",
    "        response (str): 생성된 응답\n",
    "        reference (str): 참조 답변\n",
    "        query (str): 원본 질의\n",
    "        \n",
    "    Returns:\n",
    "        str: 비교 분석\n",
    "    \"\"\"\n",
    "    # 모델에 응답 비교 방법을 지시하는 시스템 메시지\n",
    "    system_message_text = \"\"\"AI 생성 응답을 참조 답변과 비교하십시오.\n",
    "    정확성, 완전성 및 질의 관련성을 기준으로 평가하십시오.\n",
    "    생성된 응답이 참조와 얼마나 잘 일치하는지에 대한 간략한 분석(2-3 문장)을 제공하십시오.\"\"\" # system_message를 system_message_text로 변경\n",
    "\n",
    "    # 질의, AI 생성 응답 및 참조 답변을 포함하는 프롬프트 구성\n",
    "    user_prompt = f\"\"\"\n",
    "    질의: {query}\n",
    "\n",
    "    AI 생성 응답:\n",
    "    {response}\n",
    "\n",
    "    참조 답변:\n",
    "    {reference}\n",
    "\n",
    "    AI 응답이 참조와 얼마나 잘 일치합니까?\n",
    "    \"\"\" # prompt를 user_prompt로 변경\n",
    "\n",
    "    # OpenAI API에 요청하여 비교 분석 생성\n",
    "    comparison_response = client.chat.completions.create( # comparison을 comparison_response로 변경\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message_text},  # 어시스턴트를 안내하는 시스템 메시지\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 프롬프트가 포함된 사용자 메시지\n",
    "        ],\n",
    "        temperature=0.0  # 응답 생성 온도 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 비교 분석 반환\n",
    "    return comparison_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 PDF 문서에 대한 그래프 RAG 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/AI_Information.pdf에서 텍스트 추출 중...\n",
      "생성된 텍스트 청크 수: 42\n",
      "지식 그래프 구축 중...\n",
      "청크에 대한 임베딩 생성 중...\n",
      "그래프에 노드 추가 중...\n",
      "청크 1/42에 대한 개념 추출 중...\n",
      "청크 2/42에 대한 개념 추출 중...\n",
      "청크 3/42에 대한 개념 추출 중...\n",
      "청크 4/42에 대한 개념 추출 중...\n",
      "청크 5/42에 대한 개념 추출 중...\n",
      "청크 6/42에 대한 개념 추출 중...\n",
      "청크 7/42에 대한 개념 추출 중...\n",
      "청크 8/42에 대한 개념 추출 중...\n",
      "청크 9/42에 대한 개념 추출 중...\n",
      "청크 10/42에 대한 개념 추출 중...\n",
      "청크 11/42에 대한 개념 추출 중...\n",
      "청크 12/42에 대한 개념 추출 중...\n",
      "청크 13/42에 대한 개념 추출 중...\n",
      "청크 14/42에 대한 개념 추출 중...\n",
      "청크 15/42에 대한 개념 추출 중...\n",
      "청크 16/42에 대한 개념 추출 중...\n",
      "청크 17/42에 대한 개념 추출 중...\n",
      "청크 18/42에 대한 개념 추출 중...\n",
      "청크 19/42에 대한 개념 추출 중...\n",
      "청크 20/42에 대한 개념 추출 중...\n",
      "청크 21/42에 대한 개념 추출 중...\n",
      "청크 22/42에 대한 개념 추출 중...\n",
      "청크 23/42에 대한 개념 추출 중...\n",
      "청크 24/42에 대한 개념 추출 중...\n",
      "청크 25/42에 대한 개념 추출 중...\n",
      "청크 26/42에 대한 개념 추출 중...\n",
      "청크 27/42에 대한 개념 추출 중...\n",
      "청크 28/42에 대한 개념 추출 중...\n",
      "청크 29/42에 대한 개념 추출 중...\n",
      "청크 30/42에 대한 개념 추출 중...\n",
      "청크 31/42에 대한 개념 추출 중...\n",
      "청크 32/42에 대한 개념 추출 중...\n",
      "청크 33/42에 대한 개념 추출 중...\n",
      "청크 34/42에 대한 개념 추출 중...\n",
      "청크 35/42에 대한 개념 추출 중...\n",
      "청크 36/42에 대한 개념 추출 중...\n",
      "청크 37/42에 대한 개념 추출 중...\n",
      "청크 38/42에 대한 개념 추출 중...\n",
      "청크 39/42에 대한 개념 추출 중...\n",
      "청크 40/42에 대한 개념 추출 중...\n",
      "청크 41/42에 대한 개념 추출 중...\n",
      "청크 42/42에 대한 개념 추출 중...\n",
      "노드 간 엣지 생성 중...\n",
      "42개의 노드와 107개의 엣지로 지식 그래프 구축됨\n",
      "\n",
      "\n",
      "=== 질의 1/1 평가 중 ===\n",
      "질의: 자연어 처리에서 트랜스포머의 주요 적용 분야는 무엇입니까?\n",
      "'자연어 처리에서 트랜스포머의 주요 적용 분야는 무엇입니까?' 질의에 대한 그래프 탐색 중...\n",
      "5개의 노드에서 탐색 시작\n",
      "그래프 탐색 결과 9개의 관련 청크 찾음\n",
      "\n",
      "응답: 제공된 컨텍스트는 트랜스포머를 구체적으로 언급하지 않습니다. 그러나 자연어 처리(NLP)는 컴퓨터가 인간 언어를 이해, 해석 및 생성할 수 있도록 하는 AI의 한 분야라고 언급합니다. NLP 기술은 챗봇, 기계 번역, 텍스트 요약 및 감성 분석에 사용됩니다.\n",
      "\n",
      "트랜스포머 모델은 기계 번역, 텍스트 생성 및 텍스트 분류와 같은 NLP 작업에 특히 효과적인 신경망 아키텍처 유형입니다. 제공된 컨텍스트에는 명시적으로 언급되어 있지 않습니다.\n",
      "\n",
      "트랜스포머 모델에 대한 정보를 찾고 있다면 이 주제에 대한 일반적인 정보를 제공할 수 있습니다. 그러나 제공된 컨텍스트는 트랜스포머 모델을 구체적으로 다루지 않는다는 점에 유의하십시오.\n",
      "\n",
      "비교: AI 생성 응답과 참조 답변 비교:\n",
      "\n",
      "* 정확성: AI 응답은 대부분 정확하지만, 참조 답변에 언급된 RNN의 소실 그래디언트 문제에 대한 구체적인 세부 정보가 부족합니다.\n",
      "* 완전성: AI 응답은 트랜스포머와 RNN의 차이점에 대한 보다 포괄적인 개요를 제공하며, 강점과 한계를 포함합니다.\n",
      "* 질의 관련성: AI 응답은 트랜스포머와 RNN의 순차 데이터 처리를 직접 비교하므로 질의와 매우 관련이 있습니다.\n",
      "\n",
      "간략한 분석: AI 응답은 트랜스포머와 RNN 간의 보다 상세하고 포괄적인 비교를 제공하지만, 더 정확하게 만들기 위해 RNN의 소실 그래디언트 문제에 대한 구체적인 세부 정보가 추가되면 좋을 것입니다. 전반적으로 AI 응답은 참조 답변과 잘 일치하지만 약간의 개선이 있을 수 있습니다.\n",
      "\n",
      "\n",
      "=== 평가 요약 ===\n",
      "그래프 노드: 42\n",
      "그래프 엣지: 107\n",
      "\n",
      "질의 1: 자연어 처리에서 트랜스포머의 주요 적용 분야는 무엇입니까?\n",
      "경로 길이: 9\n",
      "사용된 청크: 9\n"
     ]
    }
   ],
   "source": [
    "# AI 정보가 포함된 PDF 문서 경로\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# 그래프 RAG 테스트를 위한 AI 관련 질의 정의\n",
    "query = \"자연어 처리에서 트랜스포머의 주요 적용 분야는 무엇입니까?\"\n",
    "\n",
    "# 문서 처리 및 질의 응답을 위해 그래프 RAG 파이프라인 실행\n",
    "results = graph_rag_pipeline(pdf_path, query)\n",
    "\n",
    "# 그래프 RAG 시스템에서 생성된 응답 출력\n",
    "print(\"\\n=== 답변 ===\")\n",
    "print(results[\"response\"])\n",
    "\n",
    "# 정식 평가를 위한 테스트 질의 및 참조 답변 정의\n",
    "test_queries = [\n",
    "    \"트랜스포머는 RNN과 비교하여 순차 데이터를 어떻게 처리합니까?\"\n",
    "]\n",
    "\n",
    "# 평가 목적의 참조 답변\n",
    "reference_answers = [\n",
    "    \"트랜스포머는 순환 연결 대신 자기 주의 메커니즘을 사용하여 RNN과 다르게 순차 데이터를 처리합니다. 이를 통해 트랜스포머는 순차적으로가 아닌 병렬로 모든 토큰을 처리하여 장거리 의존성을 더 효율적으로 포착하고 훈련 중 병렬화를 더 잘 수행할 수 있습니다. RNN과 달리 트랜스포머는 긴 시퀀스에서 소실 그래디언트 문제로 어려움을 겪지 않습니다.\"\n",
    "]\n",
    "\n",
    "# 테스트 질의로 그래프 RAG 시스템의 정식 평가 실행\n",
    "evaluation = evaluate_graph_rag(pdf_path, test_queries, reference_answers)\n",
    "\n",
    "# 평가 요약 통계 출력\n",
    "print(\"\\n=== 평가 요약 ===\")\n",
    "print(f\"그래프 노드: {evaluation['graph_stats']['nodes']}\")\n",
    "print(f\"그래프 엣지: {evaluation['graph_stats']['edges']}\")\n",
    "for i, result_item in enumerate(evaluation['results']): # result를 result_item으로 변경\n",
    "    print(f\"\\n질의 {i+1}: {result_item['query']}\")\n",
    "    print(f\"경로 길이: {result_item['traversal_path_length']}\")\n",
    "    print(f\"사용된 청크: {result_item['relevant_chunks_count']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

[end of 17_graph_rag.ipynb]
