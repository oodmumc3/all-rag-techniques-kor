{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## RAGì˜ ì»¨í…ìŠ¤íŠ¸ ë³´ê°• ê²€ìƒ‰\n",
    "RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ AI ì‘ë‹µì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê¸°ì¡´ ê²€ìƒ‰ ë°©ì‹ì€ ë…ë¦½ëœ í…ìŠ¤íŠ¸ ì¡°ê°(chunk)ì„ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì—, ë‹µë³€ì´ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê²€ìƒ‰ëœ ì •ë³´ê°€ ë” ë‚˜ì€ ì¼ê´€ì„±ì„ ìœ„í•´ ì£¼ë³€ ì¡°ê°(chunk)ì„ í¬í•¨í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” 'ì»¨í…ìŠ¤íŠ¸ ë³´ê°• ê²€ìƒ‰(Context-Enriched Retrieval)'ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n",
    "\n",
    "> ğŸ’¡ **ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…:** ê¸°ì¡´ RAGëŠ” ì±…ì—ì„œ íŠ¹ì • ë¬¸ì¥ í•˜ë‚˜ë§Œ ë–¼ì–´ì™€ì„œ ë³´ì—¬ì£¼ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì´ ë¬¸ì¥ë§Œìœ¼ë¡œëŠ” ì „ì²´ ë‚´ìš©ì„ íŒŒì•…í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆì£ . 'ì»¨í…ìŠ¤íŠ¸ ë³´ê°• ê²€ìƒ‰'ì€ ê·¸ ë¬¸ì¥ì˜ ì•ë’¤ ë¬¸ë‹¨ê¹Œì§€ í•¨ê»˜ ê°€ì ¸ì™€ì„œ ë³´ì—¬ì£¼ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ AIê°€ ë” í’ë¶€í•œ ë§¥ë½ì„ ì´í•´í•˜ê³  ë” ì •í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ì´ ë…¸íŠ¸ë¶ì˜ ë‹¨ê³„:\n",
    "- **ë°ì´í„° ìˆ˜ì§‘:** PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "- **ì»¨í…ìŠ¤íŠ¸ ì¤‘ì²© ë¶„í• :** ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ ì¤‘ì²©ëœ ì¡°ê°ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "- **ì„ë² ë”© ìƒì„±:** í…ìŠ¤íŠ¸ ì¡°ê°ì„ ìˆ«ì í‘œí˜„(ë²¡í„°)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ê²€ìƒ‰:** ë” ë‚˜ì€ ì™„ì „ì„±ì„ ìœ„í•´ ê´€ë ¨ ì¡°ê°ì„ ì£¼ë³€ ì¡°ê°ê³¼ í•¨ê»˜ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "- **ì‘ë‹µ ìƒì„±:** ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- **í‰ê°€:** ëª¨ë¸ ì‘ë‹µì˜ ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ê¸°\n",
    "RAGë¥¼ êµ¬í˜„í•˜ë ¤ë©´ ë¨¼ì € í…ìŠ¤íŠ¸ ë°ì´í„° ì†ŒìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): PDF íŒŒì¼ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "    str: PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    # PDF íŒŒì¼ì„ ì—½ë‹ˆë‹¤\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¹ˆ ë¬¸ìì—´ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\n",
    "\n",
    "    # PDFì˜ ê° í˜ì´ì§€ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "        text = page.get_text(\"text\")  # í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤\n",
    "        all_text += text  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ all_text ë¬¸ìì—´ì— ì¶”ê°€í•©ë‹ˆë‹¤\n",
    "\n",
    "    return all_text  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¶„í• í•˜ê¸°\n",
    "ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ë©´, ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë” ì‘ê³  ì¤‘ì²©ë˜ëŠ” ì¡°ê°(chunk)ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "\n",
    "> ğŸ’¡ **ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…:** í…ìŠ¤íŠ¸ë¥¼ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆŒ ë•Œ, ì˜ë¯¸ê°€ ì´ì–´ì§€ëŠ” ë¶€ë¶„ì´ ì˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'AëŠ” Bì´ë‹¤. ê·¸ë¦¬ê³  BëŠ” Cì´ë‹¤.'ë¼ëŠ” ë¬¸ì¥ì´ ìˆì„ ë•Œ, 'AëŠ” Bì´ë‹¤.'ì™€ 'ê·¸ë¦¬ê³  BëŠ” Cì´ë‹¤.'ë¡œ ë‚˜ëˆ„ë©´ ê° ì¡°ê°ì˜ ì˜ë¯¸ê°€ ë¶ˆì™„ì „í•´ì§‘ë‹ˆë‹¤. 'ì¤‘ì²©(Overlapping)'ì€ ê° ì¡°ê°ì˜ ëë¶€ë¶„ê³¼ ë‹¤ìŒ ì¡°ê°ì˜ ì‹œì‘ ë¶€ë¶„ì„ ê²¹ì¹˜ê²Œ ë§Œë“¤ì–´ ì´ëŸ¬í•œ ì •ë³´ ì†ì‹¤ì„ ì¤„ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë¬¸ë§¥ì´ ìœ ì§€ë˜ì–´ ê²€ìƒ‰ í’ˆì§ˆì´ í–¥ìƒë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì¤‘ì²©ì„ í¬í•¨í•˜ì—¬ nê°œì˜ ë¬¸ì ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    text (str): ë¶„í• í•  í…ìŠ¤íŠ¸.\n",
    "    n (int): ê° ì¡°ê°ì˜ ë¬¸ì ìˆ˜.\n",
    "    overlap (int): ì¡°ê° ê°„ì— ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: í…ìŠ¤íŠ¸ ì¡°ê° ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    chunks = []  # ì¡°ê°ì„ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\n",
    "    \n",
    "    # (n - overlap) í¬ê¸°ì˜ ìŠ¤í…ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # ì¸ë±ìŠ¤ ië¶€í„° i + nê¹Œì§€ì˜ í…ìŠ¤íŠ¸ ì¡°ê°ì„ chunks ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # í…ìŠ¤íŠ¸ ì¡°ê° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "ì„ë² ë”©ê³¼ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•´ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ URLê³¼ API í‚¤ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„í• \n",
    "ì´ì œ PDFë¥¼ ë¡œë“œí•˜ê³ , í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ ë‹¤ìŒ, ì¡°ê°ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 42\n",
      "\n",
      "First text chunk:\n",
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past few decades, advancements in computing power and data availability \n",
      "have significantly accelerated the development and deployment of AI. \n",
      "Historical Context \n",
      "The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. \n",
      "However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop \n",
      "in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving \n",
      "and symbolic methods. The 1980s saw a rise in exp\n"
     ]
    }
   ],
   "source": [
    "# PDF íŒŒì¼ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ 1000ì ë‹¨ìœ„ë¡œ ë¶„í• í•˜ë˜, 200ìì˜ ì¤‘ì²©ì„ ë‘¡ë‹ˆë‹¤\n",
    "text_chunks = chunk_text(extracted_text, 1000, 200)\n",
    "\n",
    "# ìƒì„±ëœ í…ìŠ¤íŠ¸ ì¡°ê°ì˜ ìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(\"Number of text chunks:\", len(text_chunks))\n",
    "\n",
    "# ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(\"\\nFirst text chunk:\")\n",
    "print(text_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ìŠ¤íŠ¸ ì¡°ê°ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±\n",
    "ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "> ğŸ’¡ **ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…:** ì„ë² ë”©ì€ 'ë‹¨ì–´ë¥¼ ìˆ«ìë¡œ ëœ ì¢Œí‘œì— í‘œì‹œí•˜ëŠ” ê²ƒ'ê³¼ ê°™ìŠµë‹ˆë‹¤. ì»´í“¨í„°ëŠ” ê¸€ìë¥¼ ì§ì ‘ ì´í•´í•˜ì§€ ëª»í•˜ë¯€ë¡œ, ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë‹¨ì–´ë‚˜ ë¬¸ì¥ì„ ê°€ê¹Œìš´ ìœ„ì¹˜ì˜ ìˆ«ìë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ 'ì¸ê³µì§€ëŠ¥'ê³¼ 'ë¨¸ì‹ ëŸ¬ë‹'ì²˜ëŸ¼ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë‹¨ì–´ë“¤ì´ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ê±°ë¦¬ì— ìœ„ì¹˜í•˜ê²Œ ë˜ì–´, ì»´í“¨í„°ê°€ ì˜ë¯¸ ê¸°ë°˜ì˜ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    text (str): ì„ë² ë”©ì„ ìƒì„±í•  ì…ë ¥ í…ìŠ¤íŠ¸.\n",
    "    model (str): ì„ë² ë”© ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸. ê¸°ë³¸ê°’ì€ \"BAAI/bge-en-icl\"ì…ë‹ˆë‹¤.\n",
    "\n",
    "    Returns:\n",
    "    dict: ì„ë² ë”©ì„ í¬í•¨í•˜ëŠ” OpenAI APIì˜ ì‘ë‹µ.\n",
    "    \"\"\"\n",
    "    # ì§€ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response  # ì„ë² ë”©ì´ í¬í•¨ëœ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì¡°ê°ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "response = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ êµ¬í˜„\n",
    "ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì£¼ë³€ ì¡°ê°ì„ í¬í•¨í•˜ë„ë¡ ê²€ìƒ‰ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "> ğŸ’¡ **ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…:** ì´ê²ƒì´ ë°”ë¡œ 'ì»¨í…ìŠ¤íŠ¸ ë³´ê°• ê²€ìƒ‰'ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì°¾ì€ ë’¤, ê·¸ ì¡°ê°ë§Œ ë–¼ì–´ì˜¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê·¸ ì•ë’¤ì— ìˆëŠ” ì¡°ê°ê¹Œì§€ í•¨ê»˜ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ AIê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ë•Œ ë” ë„“ì€ ë¬¸ë§¥ì„ ì°¸ê³ í•  ìˆ˜ ìˆì–´, í›¨ì”¬ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    vec1 (np.ndarray): ì²« ë²ˆì§¸ ë²¡í„°.\n",
    "    vec2 (np.ndarray): ë‘ ë²ˆì§¸ ë²¡í„°.\n",
    "\n",
    "    Returns:\n",
    "    float: ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„.\n",
    "    \"\"\"\n",
    "    # ë‘ ë²¡í„°ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ê³  ê° ë²¡í„°ì˜ ë…¸ë¦„(norm)ì˜ ê³±ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_enriched_search(query, text_chunks, embeddings, k=1, context_size=1):\n",
    "    \"\"\"\n",
    "    ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¡°ê°ì„ ì£¼ë³€ ì¡°ê°ê³¼ í•¨ê»˜ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    query (str): ê²€ìƒ‰ ì§ˆë¬¸.\n",
    "    text_chunks (List[str]): í…ìŠ¤íŠ¸ ì¡°ê° ë¦¬ìŠ¤íŠ¸.\n",
    "    embeddings (List[dict]): ì¡°ê° ì„ë² ë”© ë¦¬ìŠ¤íŠ¸.\n",
    "    k (int): ê²€ìƒ‰í•  ê´€ë ¨ ì¡°ê°ì˜ ìˆ˜.\n",
    "    context_size (int): í¬í•¨í•  ì£¼ë³€ ì¡°ê°ì˜ ìˆ˜.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ê°€ í¬í•¨ëœ ê´€ë ¨ í…ìŠ¤íŠ¸ ì¡°ê°.\n",
    "    \"\"\"\n",
    "    # ì§ˆë¬¸ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "    query_embedding = create_embeddings(query).data[0].embedding\n",
    "    similarity_scores = []\n",
    "\n",
    "    # ì§ˆë¬¸ê³¼ ê° í…ìŠ¤íŠ¸ ì¡°ê° ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "    for i, chunk_embedding in enumerate(embeddings):\n",
    "        # ì§ˆë¬¸ ì„ë² ë”©ê³¼ í˜„ì¬ ì¡°ê° ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "        similarity_score = cosine_similarity(np.array(query_embedding), np.array(chunk_embedding.embedding))\n",
    "        # ì¸ë±ìŠ¤ì™€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ íŠœí”Œë¡œ ì €ì¥í•©ë‹ˆë‹¤\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ê°ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤ (ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ê²ƒì´ ë¨¼ì € ì˜¤ë„ë¡)\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¡°ê°ì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "    top_index = similarity_scores[0][0]\n",
    "\n",
    "    # ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ë²”ìœ„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤\n",
    "    # 0 ë¯¸ë§Œì´ ë˜ê±°ë‚˜ text_chunksì˜ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤\n",
    "    start = max(0, top_index - context_size)\n",
    "    end = min(len(text_chunks), top_index + context_size + 1)\n",
    "\n",
    "    # ê´€ë ¨ ì¡°ê°ì„ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¡°ê°ê³¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤\n",
    "    return [text_chunks[i] for i in range(start, end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ì‹¤í–‰í•˜ê¸°\n",
    "ì´ì œ ì»¨í…ìŠ¤íŠ¸ ë³´ê°• ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "Context 1:\n",
      "nt aligns with societal values. Education and awareness campaigns inform the public \n",
      "about AI, its impacts, and its potential. \n",
      "Chapter 19: AI and Ethics \n",
      "Principles of Ethical AI \n",
      "Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
      "transparent, accountable, and beneficial to society. Key principles include respect for human \n",
      "rights, privacy, non-discrimination, and beneficence. \n",
      " \n",
      " \n",
      "Addressing Bias in AI \n",
      "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \n",
      "or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \n",
      "and ongoing monitoring and evaluation. \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on la\n",
      "=====================================\n",
      "Context 2:\n",
      "systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on large amounts of data, raising concerns about privacy and data \n",
      "protection. Ensuring responsible data handling, implementing privacy-preserving techniques, \n",
      "and complying with data protection regulations are crucial. \n",
      "Accountability and Responsibility \n",
      "Establishing accountability and responsibility for AI systems is essential for addressing potential \n",
      "harms and ensuring ethical behavior. This includes defining roles and responsibilities for \n",
      "developers, deployers, and users of AI systems. \n",
      "Chapter 20: Building Trust in AI \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "\n",
      "=====================================\n",
      "Context 3:\n",
      "to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "Ensuring that AI systems are robust and reliable is essential for building trust. This includes \n",
      "testing and validating AI models, monitoring their performance, and addressing potential \n",
      "vulnerabilities. \n",
      "User Control and Agency \n",
      "Empowering users with control over AI systems and providing them with agency in their \n",
      "interactions with AI enhances trust. This includes allowing users to customize AI settings, \n",
      "understand how their data is used, and opt out of AI-driven features. \n",
      "Ethical Design and Development \n",
      "Incorporating ethical considerations into the design and development of AI systems is crucial for \n",
      "building trust. This includes conducting ethical impact assessments, engaging stakeholders, and \n",
      "adhering to ethical guidelines and standards. \n",
      "Public Engagement and Education \n",
      "Engaging th\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# JSON íŒŒì¼ì—ì„œ ê²€ì¦ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤\n",
    "with open('data/val.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ë°ì´í„°ì…‹ì—ì„œ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ì—¬ ì¿¼ë¦¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
    "query = data[0]['question']\n",
    "\n",
    "# ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¡°ê°ê³¼ ê·¸ ì£¼ë³€ ì¡°ê°ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "# ë§¤ê°œë³€ìˆ˜:\n",
    "# - query: ê²€ìƒ‰í•  ì§ˆë¬¸\n",
    "# - text_chunks: PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ì¡°ê°\n",
    "# - response.data: í…ìŠ¤íŠ¸ ì¡°ê°ì˜ ì„ë² ë”©\n",
    "# - k=1: ê°€ì¥ ì¼ì¹˜í•˜ëŠ” í•­ëª© 1ê°œë¥¼ ë°˜í™˜\n",
    "# - context_size=1: ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìµœìƒìœ„ ì¼ì¹˜ í•­ëª©ì˜ ì•ë’¤ë¡œ 1ê°œì˜ ì¡°ê°ì„ í¬í•¨\n",
    "top_chunks = context_enriched_search(query, text_chunks, response.data, k=1, context_size=1)\n",
    "\n",
    "# ì°¸ê³ ìš©ìœ¼ë¡œ ì§ˆë¬¸ì„ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(\"Query:\", query)\n",
    "# ê²€ìƒ‰ëœ ê° ì¡°ê°ì„ ì œëª©ê³¼ êµ¬ë¶„ ê¸°í˜¸ì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"Context {i + 1}:\\n{chunk}\\n=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±í•˜ê¸°\n",
    "ì´ì œ LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI ì–´ì‹œìŠ¤í„´íŠ¸ì— ëŒ€í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤\n",
    "system_prompt = \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œë§Œ ì—„ê²©í•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ë‹µë³€ì„ ë„ì¶œí•  ìˆ˜ ì—†ëŠ” ê²½ìš°, 'ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.\"\n",
    "\n",
    "def generate_response(system_prompt, user_message, model=\"meta-llama/Llama-3.2-3B-Instruct\"):\n",
    "    \"\"\"\n",
    "    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "    system_prompt (str): AIì˜ í–‰ë™ì„ ì•ˆë‚´í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸.\n",
    "    user_message (str): ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ë˜ëŠ” ì§ˆë¬¸.\n",
    "    model (str): ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸. ê¸°ë³¸ê°’ì€ \"meta-llama/Llama-2-7B-chat-hf\"ì…ë‹ˆë‹¤.\n",
    "\n",
    "    Returns:\n",
    "    dict: AI ëª¨ë¸ì˜ ì‘ë‹µ.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# ìµœìƒìœ„ ì¡°ê°ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
    "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
    "\n",
    "# AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "ai_response = generate_response(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI ì‘ë‹µ í‰ê°€í•˜ê¸°\n",
    "AIì˜ ì‘ë‹µì„ ê¸°ëŒ€ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the evaluation criteria, I would assign a score of 0.8 to the AI assistant's response.\n",
      "\n",
      "The response is very close to the true response, and it correctly conveys the main idea of Explainable AI (XAI) and its importance. The AI assistant's response is also well-structured and easy to understand, which is a positive aspect.\n",
      "\n",
      "However, there are a few minor differences between the AI assistant's response and the true response. The AI assistant's response is slightly more detailed and provides additional points (1-4) that are not present in the true response. Additionally, the AI assistant's response uses more formal language and phrases, such as \"In essence,\" which is not present in the true response.\n",
      "\n",
      "Despite these minor differences, the AI assistant's response is still very close to the true response, and it effectively conveys the main idea of XAI and its importance. Therefore, I would assign a score of 0.8.\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€ ì‹œìŠ¤í…œì— ëŒ€í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤\n",
    "evaluate_system_prompt = \"ë‹¹ì‹ ì€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ í‰ê°€í•˜ëŠ” ì§€ëŠ¥í˜• í‰ê°€ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì´ ì‹¤ì œ ì‘ë‹µê³¼ ë§¤ìš° ê°€ê¹Œìš°ë©´ 1ì ì„ ë¶€ì—¬í•˜ì„¸ìš”. ì‘ë‹µì´ ì‹¤ì œ ì‘ë‹µê³¼ ë¹„êµí•˜ì—¬ ë¶€ì •í™•í•˜ê±°ë‚˜ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šìœ¼ë©´ 0ì ì„ ë¶€ì—¬í•˜ì„¸ìš”. ì‘ë‹µì´ ì‹¤ì œ ì‘ë‹µê³¼ ë¶€ë¶„ì ìœ¼ë¡œ ì¼ì¹˜í•˜ë©´ 0.5ì ì„ ë¶€ì—¬í•˜ì„¸ìš”.\"\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸, AI ì‘ë‹µ, ì‹¤ì œ ì‘ë‹µ ë° í‰ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ í‰ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
    "\n",
    "# í‰ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í‰ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤\n",
    "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
    "\n",
    "# í‰ê°€ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(evaluation_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}