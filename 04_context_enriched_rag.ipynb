{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## RAG의 컨텍스트 보강 검색\n",
    "RAG(Retrieval-Augmented Generation)는 외부 소스에서 관련 지식을 검색하여 AI 응답의 품질을 향상시킵니다. 기존 검색 방식은 독립된 텍스트 조각(chunk)을 반환하기 때문에, 답변이 불완전할 수 있습니다.\n",
    "\n",
    "이 문제를 해결하기 위해, 검색된 정보가 더 나은 일관성을 위해 주변 조각(chunk)을 포함하도록 보장하는 '컨텍스트 보강 검색(Context-Enriched Retrieval)'을 소개합니다.\n",
    "\n",
    "> 💡 **초보자를 위한 설명:** 기존 RAG는 책에서 특정 문장 하나만 떼어와서 보여주는 것과 같습니다. 이 문장만으로는 전체 내용을 파악하기 어려울 수 있죠. '컨텍스트 보강 검색'은 그 문장의 앞뒤 문단까지 함께 가져와서 보여주는 것과 같습니다. 이렇게 하면 AI가 더 풍부한 맥락을 이해하고 더 정확하고 완전한 답변을 생성하는 데 도움이 됩니다.\n",
    "\n",
    "### 이 노트북의 단계:\n",
    "- **데이터 수집:** PDF에서 텍스트를 추출합니다.\n",
    "- **컨텍스트 중첩 분할:** 컨텍스트를 보존하기 위해 텍스트를 중첩된 조각으로 분할합니다.\n",
    "- **임베딩 생성:** 텍스트 조각을 숫자 표현(벡터)으로 변환합니다.\n",
    "- **컨텍스트 인식 검색:** 더 나은 완전성을 위해 관련 조각을 주변 조각과 함께 검색합니다.\n",
    "- **응답 생성:** 검색된 컨텍스트를 기반으로 언어 모델을 사용하여 응답을 생성합니다.\n",
    "- **평가:** 모델 응답의 정확도를 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "필요한 라이브러리를 가져오는 것으로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF 파일에서 텍스트 추출하기\n",
    "RAG를 구현하려면 먼저 텍스트 데이터 소스가 필요합니다. 여기서는 PyMuPDF 라이브러리를 사용하여 PDF 파일에서 텍스트를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 추출합니다.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): PDF 파일 경로.\n",
    "\n",
    "    Returns:\n",
    "    str: PDF에서 추출된 텍스트.\n",
    "    \"\"\"\n",
    "    # PDF 파일을 엽니다\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 추출된 텍스트를 저장할 빈 문자열을 초기화합니다\n",
    "\n",
    "    # PDF의 각 페이지를 반복합니다\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # 페이지를 가져옵니다\n",
    "        text = page.get_text(\"text\")  # 페이지에서 텍스트를 추출합니다\n",
    "        all_text += text  # 추출된 텍스트를 all_text 문자열에 추가합니다\n",
    "\n",
    "    return all_text  # 추출된 텍스트를 반환합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추출된 텍스트 분할하기\n",
    "추출된 텍스트가 준비되면, 검색 정확도를 높이기 위해 더 작고 중첩되는 조각(chunk)으로 나눕니다.\n",
    "\n",
    "> 💡 **초보자를 위한 설명:** 텍스트를 조각으로 나눌 때, 의미가 이어지는 부분이 잘릴 수 있습니다. 예를 들어, 'A는 B이다. 그리고 B는 C이다.'라는 문장이 있을 때, 'A는 B이다.'와 '그리고 B는 C이다.'로 나누면 각 조각의 의미가 불완전해집니다. '중첩(Overlapping)'은 각 조각의 끝부분과 다음 조각의 시작 부분을 겹치게 만들어 이러한 정보 손실을 줄이는 기법입니다. 이렇게 하면 문맥이 유지되어 검색 품질이 향상됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 중첩을 포함하여 n개의 문자 세그먼트로 분할합니다.\n",
    "\n",
    "    Args:\n",
    "    text (str): 분할할 텍스트.\n",
    "    n (int): 각 조각의 문자 수.\n",
    "    overlap (int): 조각 간에 겹치는 문자 수.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 텍스트 조각 리스트.\n",
    "    \"\"\"\n",
    "    chunks = []  # 조각을 저장할 빈 리스트를 초기화합니다\n",
    "    \n",
    "    # (n - overlap) 크기의 스텝으로 텍스트를 반복합니다\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # 인덱스 i부터 i + n까지의 텍스트 조각을 chunks 리스트에 추가합니다\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # 텍스트 조각 리스트를 반환합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API 클라이언트 설정\n",
    "임베딩과 응답을 생성하기 위해 OpenAI 클라이언트를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 URL과 API 키로 OpenAI 클라이언트를 초기화합니다\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 환경 변수에서 API 키를 가져옵니다\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF 파일에서 텍스트 추출 및 분할\n",
    "이제 PDF를 로드하고, 텍스트를 추출한 다음, 조각으로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 42\n",
      "\n",
      "First text chunk:\n",
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past few decades, advancements in computing power and data availability \n",
      "have significantly accelerated the development and deployment of AI. \n",
      "Historical Context \n",
      "The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. \n",
      "However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop \n",
      "in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving \n",
      "and symbolic methods. The 1980s saw a rise in exp\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일 경로를 정의합니다\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# PDF 파일에서 텍스트를 추출합니다\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# 추출된 텍스트를 1000자 단위로 분할하되, 200자의 중첩을 둡니다\n",
    "text_chunks = chunk_text(extracted_text, 1000, 200)\n",
    "\n",
    "# 생성된 텍스트 조각의 수를 출력합니다\n",
    "print(\"Number of text chunks:\", len(text_chunks))\n",
    "\n",
    "# 첫 번째 텍스트 조각을 출력합니다\n",
    "print(\"\\nFirst text chunk:\")\n",
    "print(text_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 조각에 대한 임베딩 생성\n",
    "임베딩은 텍스트를 숫자 벡터로 변환하여 효율적인 유사도 검색을 가능하게 합니다.\n",
    "\n",
    "> 💡 **초보자를 위한 설명:** 임베딩은 '단어를 숫자로 된 좌표에 표시하는 것'과 같습니다. 컴퓨터는 글자를 직접 이해하지 못하므로, 의미가 비슷한 단어나 문장을 가까운 위치의 숫자로 바꿔줍니다. 이렇게 하면 '인공지능'과 '머신러닝'처럼 의미가 비슷한 단어들이 벡터 공간에서 가까운 거리에 위치하게 되어, 컴퓨터가 의미 기반의 유사도 검색을 효율적으로 수행할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    지정된 OpenAI 모델을 사용하여 주어진 텍스트에 대한 임베딩을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "    text (str): 임베딩을 생성할 입력 텍스트.\n",
    "    model (str): 임베딩 생성에 사용할 모델. 기본값은 \"BAAI/bge-en-icl\"입니다.\n",
    "\n",
    "    Returns:\n",
    "    dict: 임베딩을 포함하는 OpenAI API의 응답.\n",
    "    \"\"\"\n",
    "    # 지정된 모델을 사용하여 입력 텍스트에 대한 임베딩을 생성합니다\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response  # 임베딩이 포함된 응답을 반환합니다\n",
    "\n",
    "# 텍스트 조각에 대한 임베딩을 생성합니다\n",
    "response = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨텍스트 인식 의미론적 검색 구현\n",
    "더 나은 컨텍스트를 위해 주변 조각을 포함하도록 검색을 수정합니다.\n",
    "\n",
    "> 💡 **초보자를 위한 설명:** 이것이 바로 '컨텍스트 보강 검색'의 핵심입니다. 사용자의 질문과 가장 관련성이 높은 텍스트 조각을 찾은 뒤, 그 조각만 떼어오는 것이 아니라 그 앞뒤에 있는 조각까지 함께 가져옵니다. 이렇게 하면 AI가 질문에 대한 답변을 생성할 때 더 넓은 문맥을 참고할 수 있어, 훨씬 자연스럽고 정확한 답변을 할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    두 벡터 간의 코사인 유사도를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    vec1 (np.ndarray): 첫 번째 벡터.\n",
    "    vec2 (np.ndarray): 두 번째 벡터.\n",
    "\n",
    "    Returns:\n",
    "    float: 두 벡터 간의 코사인 유사도.\n",
    "    \"\"\"\n",
    "    # 두 벡터의 내적을 계산하고 각 벡터의 노름(norm)의 곱으로 나눕니다\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_enriched_search(query, text_chunks, embeddings, k=1, context_size=1):\n",
    "    \"\"\"\n",
    "    가장 관련성 높은 조각을 주변 조각과 함께 검색합니다.\n",
    "\n",
    "    Args:\n",
    "    query (str): 검색 질문.\n",
    "    text_chunks (List[str]): 텍스트 조각 리스트.\n",
    "    embeddings (List[dict]): 조각 임베딩 리스트.\n",
    "    k (int): 검색할 관련 조각의 수.\n",
    "    context_size (int): 포함할 주변 조각의 수.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 컨텍스트 정보가 포함된 관련 텍스트 조각.\n",
    "    \"\"\"\n",
    "    # 질문을 임베딩 벡터로 변환합니다\n",
    "    query_embedding = create_embeddings(query).data[0].embedding\n",
    "    similarity_scores = []\n",
    "\n",
    "    # 질문과 각 텍스트 조각 임베딩 간의 유사도 점수를 계산합니다\n",
    "    for i, chunk_embedding in enumerate(embeddings):\n",
    "        # 질문 임베딩과 현재 조각 임베딩 간의 코사인 유사도를 계산합니다\n",
    "        similarity_score = cosine_similarity(np.array(query_embedding), np.array(chunk_embedding.embedding))\n",
    "        # 인덱스와 유사도 점수를 튜플로 저장합니다\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    # 유사도 점수를 기준으로 조각을 내림차순으로 정렬합니다 (유사도가 가장 높은 것이 먼저 오도록)\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 관련성 높은 조각의 인덱스를 가져옵니다\n",
    "    top_index = similarity_scores[0][0]\n",
    "\n",
    "    # 컨텍스트 포함 범위를 정의합니다\n",
    "    # 0 미만이 되거나 text_chunks의 길이를 초과하지 않도록 보장합니다\n",
    "    start = max(0, top_index - context_size)\n",
    "    end = min(len(text_chunks), top_index + context_size + 1)\n",
    "\n",
    "    # 관련 조각을 주변 컨텍스트 조각과 함께 반환합니다\n",
    "    return [text_chunks[i] for i in range(start, end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨텍스트 검색을 사용하여 질문 실행하기\n",
    "이제 컨텍스트 보강 검색을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "Context 1:\n",
      "nt aligns with societal values. Education and awareness campaigns inform the public \n",
      "about AI, its impacts, and its potential. \n",
      "Chapter 19: AI and Ethics \n",
      "Principles of Ethical AI \n",
      "Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
      "transparent, accountable, and beneficial to society. Key principles include respect for human \n",
      "rights, privacy, non-discrimination, and beneficence. \n",
      " \n",
      " \n",
      "Addressing Bias in AI \n",
      "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \n",
      "or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \n",
      "and ongoing monitoring and evaluation. \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on la\n",
      "=====================================\n",
      "Context 2:\n",
      "systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on large amounts of data, raising concerns about privacy and data \n",
      "protection. Ensuring responsible data handling, implementing privacy-preserving techniques, \n",
      "and complying with data protection regulations are crucial. \n",
      "Accountability and Responsibility \n",
      "Establishing accountability and responsibility for AI systems is essential for addressing potential \n",
      "harms and ensuring ethical behavior. This includes defining roles and responsibilities for \n",
      "developers, deployers, and users of AI systems. \n",
      "Chapter 20: Building Trust in AI \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "\n",
      "=====================================\n",
      "Context 3:\n",
      "to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "Ensuring that AI systems are robust and reliable is essential for building trust. This includes \n",
      "testing and validating AI models, monitoring their performance, and addressing potential \n",
      "vulnerabilities. \n",
      "User Control and Agency \n",
      "Empowering users with control over AI systems and providing them with agency in their \n",
      "interactions with AI enhances trust. This includes allowing users to customize AI settings, \n",
      "understand how their data is used, and opt out of AI-driven features. \n",
      "Ethical Design and Development \n",
      "Incorporating ethical considerations into the design and development of AI systems is crucial for \n",
      "building trust. This includes conducting ethical impact assessments, engaging stakeholders, and \n",
      "adhering to ethical guidelines and standards. \n",
      "Public Engagement and Education \n",
      "Engaging th\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일에서 검증 데이터셋을 로드합니다\n",
    "with open('data/val.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 데이터셋에서 첫 번째 질문을 추출하여 쿼리로 사용합니다\n",
    "query = data[0]['question']\n",
    "\n",
    "# 컨텍스트를 위해 가장 관련성 높은 조각과 그 주변 조각을 검색합니다\n",
    "# 매개변수:\n",
    "# - query: 검색할 질문\n",
    "# - text_chunks: PDF에서 추출한 텍스트 조각\n",
    "# - response.data: 텍스트 조각의 임베딩\n",
    "# - k=1: 가장 일치하는 항목 1개를 반환\n",
    "# - context_size=1: 컨텍스트를 위해 최상위 일치 항목의 앞뒤로 1개의 조각을 포함\n",
    "top_chunks = context_enriched_search(query, text_chunks, response.data, k=1, context_size=1)\n",
    "\n",
    "# 참고용으로 질문을 출력합니다\n",
    "print(\"Query:\", query)\n",
    "# 검색된 각 조각을 제목과 구분 기호와 함께 출력합니다\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"Context {i + 1}:\\n{chunk}\\n=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색된 컨텍스트를 사용하여 응답 생성하기\n",
    "이제 LLM을 사용하여 응답을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 어시스턴트에 대한 시스템 프롬프트를 정의합니다\n",
    "system_prompt = \"당신은 주어진 컨텍스트를 기반으로만 엄격하게 답변하는 AI 어시스턴트입니다. 제공된 컨텍스트에서 직접 답변을 도출할 수 없는 경우, '답변하기에 충분한 정보가 없습니다.'라고 응답하세요.\"\n",
    "\n",
    "def generate_response(system_prompt, user_message, model=\"meta-llama/Llama-3.2-3B-Instruct\"):\n",
    "    \"\"\"\n",
    "    시스템 프롬프트와 사용자 메시지를 기반으로 AI 모델로부터 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "    system_prompt (str): AI의 행동을 안내하는 시스템 프롬프트.\n",
    "    user_message (str): 사용자의 메시지 또는 질문.\n",
    "    model (str): 응답 생성에 사용할 모델. 기본값은 \"meta-llama/Llama-2-7B-chat-hf\"입니다.\n",
    "\n",
    "    Returns:\n",
    "    dict: AI 모델의 응답.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# 최상위 조각을 기반으로 사용자 프롬프트를 생성합니다\n",
    "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
    "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
    "\n",
    "# AI 응답을 생성합니다\n",
    "ai_response = generate_response(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 응답 평가하기\n",
    "AI의 응답을 기대 답변과 비교하여 점수를 매깁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the evaluation criteria, I would assign a score of 0.8 to the AI assistant's response.\n",
      "\n",
      "The response is very close to the true response, and it correctly conveys the main idea of Explainable AI (XAI) and its importance. The AI assistant's response is also well-structured and easy to understand, which is a positive aspect.\n",
      "\n",
      "However, there are a few minor differences between the AI assistant's response and the true response. The AI assistant's response is slightly more detailed and provides additional points (1-4) that are not present in the true response. Additionally, the AI assistant's response uses more formal language and phrases, such as \"In essence,\" which is not present in the true response.\n",
      "\n",
      "Despite these minor differences, the AI assistant's response is still very close to the true response, and it effectively conveys the main idea of XAI and its importance. Therefore, I would assign a score of 0.8.\n"
     ]
    }
   ],
   "source": [
    "# 평가 시스템에 대한 시스템 프롬프트를 정의합니다\n",
    "evaluate_system_prompt = \"당신은 AI 어시스턴트의 응답을 평가하는 지능형 평가 시스템입니다. AI 어시스턴트의 응답이 실제 응답과 매우 가까우면 1점을 부여하세요. 응답이 실제 응답과 비교하여 부정확하거나 만족스럽지 않으면 0점을 부여하세요. 응답이 실제 응답과 부분적으로 일치하면 0.5점을 부여하세요.\"\n",
    "\n",
    "# 사용자 질문, AI 응답, 실제 응답 및 평가 시스템 프롬프트를 결합하여 평가 프롬프트를 생성합니다\n",
    "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
    "\n",
    "# 평가 시스템 프롬프트와 평가 프롬프트를 사용하여 평가 응답을 생성합니다\n",
    "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
    "\n",
    "# 평가 응답을 출력합니다\n",
    "print(evaluation_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}