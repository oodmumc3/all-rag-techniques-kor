{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 퓨전 검색: 벡터 검색과 키워드 검색 결합\n",
    "\n",
    "이 노트북에서는 의미론적 벡터 검색과 키워드 기반 BM25 검색의 장점을 결합한 퓨전 검색 시스템을 구현합니다. 이 접근 방식은 개념적 유사성과 정확한 키워드 일치를 모두 포착하여 검색 품질을 향상시킵니다.\n",
    "퓨전 검색(Fusion Retrieval)은 여러 검색 방법의 결과를 종합하여 최종 검색 결과를 도출하는 방식입니다. 일반적으로 의미 기반 검색(벡터 검색)과 키워드 기반 검색(예: BM25)을 함께 사용하여 각 방식의 장점을 취하고 단점을 보완합니다.\n",
    "\n",
    "## 퓨전 검색이 중요한 이유\n",
    "\n",
    "기존 RAG 시스템은 일반적으로 벡터 검색에만 의존하지만 다음과 같은 한계가 있습니다:\n",
    "\n",
    "- 벡터 검색은 의미론적 유사성에는 뛰어나지만 정확한 키워드 일치를 놓칠 수 있습니다.\n",
    "- 키워드 검색은 특정 용어에는 유용하지만 의미론적 이해가 부족합니다.\n",
    "- 서로 다른 질의는 서로 다른 검색 방법에서 더 나은 성능을 보입니다.\n",
    "\n",
    "퓨전 검색은 다음을 통해 두 가지 장점을 모두 제공합니다:\n",
    "\n",
    "- 벡터 기반 검색과 키워드 기반 검색을 모두 수행합니다.\n",
    "- 각 접근 방식의 점수를 정규화합니다.\n",
    "- 가중치 공식을 사용하여 결합합니다.\n",
    "- 결합된 점수를 기준으로 문서를 순위 매깁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "필요한 라이브러리를 가져오는 것으로 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi  # BM25 라이브러리\n",
    "import fitz  # PyMuPDF\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity # 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API 클라이언트 설정\n",
    "임베딩과 응답을 생성하기 위해 OpenAI 클라이언트를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 URL과 API 키로 OpenAI 클라이언트 초기화\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 환경 변수에서 API 키 검색\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트 내용을 추출합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        \n",
    "    Returns:\n",
    "        str: 추출된 텍스트 내용\n",
    "    \"\"\"\n",
    "    print(f\"{pdf_path}에서 텍스트 추출 중...\")  # 처리 중인 PDF 경로 출력\n",
    "    pdf_document = fitz.open(pdf_path)  # PyMuPDF를 사용하여 PDF 파일 열기\n",
    "    text_content = \"\"  # 추출된 텍스트를 저장할 빈 문자열 초기화 (text를 text_content로 변경)\n",
    "    \n",
    "    # PDF의 각 페이지 반복\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]  # 페이지 객체 가져오기\n",
    "        text_content += page.get_text()  # 페이지에서 텍스트 추출하여 문자열에 추가\n",
    "    \n",
    "    return text_content  # 추출된 텍스트 내용 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 중첩되는 청크로 분할합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 청킹할 입력 텍스트\n",
    "        chunk_size (int): 각 청크의 문자 크기\n",
    "        chunk_overlap (int): 청크 간 문자 중첩\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 텍스트와 메타데이터를 포함하는 청크 목록\n",
    "    \"\"\"\n",
    "    chunks_list = []  # 청크를 저장할 빈 리스트 초기화 (chunks를 chunks_list로 변경)\n",
    "    \n",
    "    # 지정된 청크 크기와 중첩으로 텍스트 반복\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunk_content = text[i:i + chunk_size]  # 지정된 크기의 청크 추출 (chunk를 chunk_content로 변경)\n",
    "        if chunk_content:  # 빈 청크를 추가하지 않도록 확인\n",
    "            chunk_data_item = { # chunk_data를 chunk_data_item으로 변경\n",
    "                \"text\": chunk_content,  # 청크 텍스트\n",
    "                \"metadata\": {\n",
    "                    \"start_char\": i,  # 청크의 시작 문자 인덱스\n",
    "                    \"end_char\": i + len(chunk_content)  # 청크의 끝 문자 인덱스\n",
    "                }\n",
    "            }\n",
    "            chunks_list.append(chunk_data_item)  # 청크 데이터를 리스트에 추가\n",
    "    \n",
    "    print(f\"생성된 텍스트 청크 수: {len(chunks_list)}\")  # 생성된 청크 수 출력\n",
    "    return chunks_list  # 청크 목록 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    추가 공백 및 특수 문자를 제거하여 텍스트를 정리합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 입력 텍스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 정리된 텍스트\n",
    "    \"\"\"\n",
    "    # 여러 공백 문자(줄 바꿈 및 탭 포함)를 단일 공백으로 바꿉니다.\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # 탭 및 줄 바꿈 문자를 공백으로 바꾸어 일반적인 OCR 문제를 수정합니다.\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    \n",
    "    # 앞뒤 공백을 제거하고 단어 사이에 단일 공백만 있도록 합니다.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 저장소 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에 대한 임베딩을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        texts (str 또는 List[str]): 입력 텍스트\n",
    "        model (str): 임베딩 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: 임베딩 벡터\n",
    "    \"\"\"\n",
    "    # 문자열 및 리스트 입력 모두 처리\n",
    "    input_texts_list = texts if isinstance(texts, list) else [texts] # input_texts를 input_texts_list로 변경\n",
    "    \n",
    "    # 필요한 경우 배치로 처리 (OpenAI API 제한)\n",
    "    batch_size = 100\n",
    "    all_embeddings_list = [] # all_embeddings를 all_embeddings_list로 변경\n",
    "    \n",
    "    # 입력 텍스트를 배치로 반복\n",
    "    for i in range(0, len(input_texts_list), batch_size):\n",
    "        batch_texts = input_texts_list[i:i + batch_size]  # 현재 텍스트 배치 가져오기 (batch를 batch_texts로 변경)\n",
    "        \n",
    "        # 현재 배치에 대한 임베딩 생성\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch_texts\n",
    "        )\n",
    "        \n",
    "        # 응답에서 임베딩 추출\n",
    "        batch_embeddings_list = [item.embedding for item in response.data] # batch_embeddings를 batch_embeddings_list로 변경\n",
    "        all_embeddings_list.extend(batch_embeddings_list)  # 배치 임베딩을 리스트에 추가\n",
    "    \n",
    "    # 입력이 단일 문자열이었으면 첫 번째 임베딩만 반환\n",
    "    if isinstance(texts, str):\n",
    "        return all_embeddings_list[0]\n",
    "    \n",
    "    # 그렇지 않으면 모든 임베딩 반환\n",
    "    return all_embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    NumPy를 사용한 간단한 벡터 저장소 구현.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # 임베딩 벡터를 저장할 리스트\n",
    "        self.texts = []  # 텍스트 내용을 저장할 리스트\n",
    "        self.metadata = []  # 메타데이터를 저장할 리스트\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        벡터 저장소에 항목을 추가합니다.\n",
    "        \n",
    "        Args:\n",
    "            text (str): 텍스트 내용\n",
    "            embedding (List[float]): 임베딩 벡터\n",
    "            metadata (Dict, optional): 추가 메타데이터\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 임베딩 벡터 추가\n",
    "        self.texts.append(text)  # 텍스트 내용 추가\n",
    "        self.metadata.append(metadata or {})  # 메타데이터 추가 (None이면 빈 딕셔너리)\n",
    "    \n",
    "    def add_items(self, items, embeddings):\n",
    "        \"\"\"\n",
    "        벡터 저장소에 여러 항목을 추가합니다.\n",
    "        \n",
    "        Args:\n",
    "            items (List[Dict]): 텍스트 항목 목록\n",
    "            embeddings (List[List[float]]): 임베딩 벡터 목록\n",
    "        \"\"\"\n",
    "        for i, (item_data, embedding_vector) in enumerate(zip(items, embeddings)): # item, embedding을 item_data, embedding_vector로 변경\n",
    "            self.add_item(\n",
    "                text=item_data[\"text\"],  # 항목에서 텍스트 추출\n",
    "                embedding=embedding_vector,  # 해당 임베딩 사용\n",
    "                metadata={**item_data.get(\"metadata\", {}), \"index\": i}  # 항목 메타데이터와 인덱스 병합\n",
    "            )\n",
    "    \n",
    "    def similarity_search_with_scores(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        유사도 점수와 함께 질의 임베딩과 가장 유사한 항목을 찾습니다.\n",
    "        \n",
    "        Args:\n",
    "            query_embedding (List[float]): 질의 임베딩 벡터\n",
    "            k (int): 반환할 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[Dict, float]]: 점수가 있는 상위 k개의 가장 유사한 항목\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 저장된 벡터가 없으면 빈 리스트 반환\n",
    "        \n",
    "        # 질의 임베딩을 numpy 배열로 변환\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 코사인 유사도를 사용하여 유사도 계산\n",
    "        similarities = []\n",
    "        for i, vector_item in enumerate(self.vectors): # vector를 vector_item으로 변경\n",
    "            similarity = cosine_similarity([query_vector], [vector_item])[0][0]  # 코사인 유사도 계산\n",
    "            similarities.append((i, similarity))  # 인덱스와 유사도 점수 추가\n",
    "        \n",
    "        # 유사도 기준으로 정렬 (내림차순)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 점수가 있는 상위 k개 결과 반환\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score_value = similarities[i] # score를 score_value로 변경\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 인덱스로 텍스트 검색\n",
    "                \"metadata\": self.metadata[idx],  # 인덱스로 메타데이터 검색\n",
    "                \"similarity\": float(score_value)  # 유사도 점수 추가 (float으로 변환)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_all_documents(self):\n",
    "        \"\"\"\n",
    "        저장소의 모든 문서를 가져옵니다.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: 모든 문서\n",
    "        \"\"\"\n",
    "        return [{\"text\": text_content, \"metadata\": meta_info} for text_content, meta_info in zip(self.texts, self.metadata)]  # 텍스트와 메타데이터 결합 (text, meta를 text_content, meta_info로 변경)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 구현\n",
    "BM25는 키워드 기반 검색 알고리즘으로, 문서 내 단어 빈도와 문서 빈도를 고려하여 관련성을 계산합니다. 벡터 검색과 상호 보완적으로 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(chunks):\n",
    "    \"\"\"\n",
    "    주어진 청크에서 BM25 인덱스를 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[Dict]): 텍스트 청크 목록\n",
    "        \n",
    "    Returns:\n",
    "        BM25Okapi: BM25 인덱스\n",
    "    \"\"\"\n",
    "    # 각 청크에서 텍스트 추출\n",
    "    texts = [chunk_item[\"text\"] for chunk_item in chunks] # chunk를 chunk_item으로 변경\n",
    "    \n",
    "    # 공백을 기준으로 각 문서를 토큰화\n",
    "    tokenized_docs = [text_content.split() for text_content in texts] # text를 text_content로 변경\n",
    "    \n",
    "    # 토큰화된 문서를 사용하여 BM25 인덱스 생성\n",
    "    bm25_index = BM25Okapi(tokenized_docs) # bm25를 bm25_index로 변경\n",
    "    \n",
    "    # BM25 인덱스의 문서 수 출력\n",
    "    print(f\"{len(texts)}개의 문서로 BM25 인덱스 생성됨\")\n",
    "    \n",
    "    return bm25_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(bm25, chunks, query, k=5):\n",
    "    \"\"\"\n",
    "    질의로 BM25 인덱스를 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        bm25 (BM25Okapi): BM25 인덱스\n",
    "        chunks (List[Dict]): 텍스트 청크 목록\n",
    "        query (str): 질의 문자열\n",
    "        k (int): 반환할 결과 수\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 점수가 있는 상위 k개 결과\n",
    "    \"\"\"\n",
    "    # 질의를 개별 단어로 토큰화\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # 인덱싱된 문서에 대한 질의 토큰의 BM25 점수 가져오기\n",
    "    doc_scores = bm25.get_scores(query_tokens) # scores를 doc_scores로 변경\n",
    "    \n",
    "    # 점수가 있는 결과를 저장할 빈 리스트 초기화\n",
    "    results_with_scores = [] # results를 results_with_scores로 변경\n",
    "    \n",
    "    # 점수와 해당 청크 반복\n",
    "    for i, score_value in enumerate(doc_scores): # score를 score_value로 변경\n",
    "        # 원본을 수정하지 않도록 메타데이터 복사\n",
    "        metadata_info = chunks[i].get(\"metadata\", {}).copy() # metadata를 metadata_info로 변경\n",
    "        # 메타데이터에 인덱스 추가\n",
    "        metadata_info[\"index\"] = i\n",
    "        \n",
    "        results_with_scores.append({\n",
    "            \"text\": chunks[i][\"text\"],\n",
    "            \"metadata\": metadata_info,  # 인덱스가 있는 메타데이터 추가\n",
    "            \"bm25_score\": float(score_value) # 점수를 float으로 변환\n",
    "        })\n",
    "    \n",
    "    # BM25 점수를 기준으로 결과 내림차순 정렬\n",
    "    results_with_scores.sort(key=lambda x: x[\"bm25_score\"], reverse=True)\n",
    "    \n",
    "    # 상위 k개 결과 반환\n",
    "    return results_with_scores[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퓨전 검색 함수\n",
    "벡터 검색과 BM25 검색 결과를 결합합니다. 각 검색 방법의 점수를 정규화하고, 가중치를 적용하여 최종 점수를 계산한 후 순위를 매깁니다. `alpha` 값으로 각 검색 방법의 중요도를 조절할 수 있습니다 (alpha가 1이면 벡터 검색만, 0이면 BM25 검색만 사용)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    벡터 기반 검색과 BM25 검색을 결합한 퓨전 검색을 수행합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 질의 문자열\n",
    "        chunks (List[Dict]): 원본 텍스트 청크\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 반환할 결과 수\n",
    "        alpha (float): 벡터 점수의 가중치 (0-1), 1-alpha는 BM25 가중치\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 결합된 점수를 기준으로 한 상위 k개 결과\n",
    "    \"\"\"\n",
    "    print(f\"'{query}' 질의에 대한 퓨전 검색 수행 중...\")\n",
    "    \n",
    "    # 0으로 나누기 방지를 위한 작은 엡실론 정의\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # 벡터 검색 결과 가져오기\n",
    "    query_embedding = create_embeddings(query)  # 질의에 대한 임베딩 생성\n",
    "    vector_search_results = vector_store.similarity_search_with_scores(query_embedding, k=len(chunks))  # 벡터 검색 수행 (vector_results를 vector_search_results로 변경)\n",
    "    \n",
    "    # BM25 검색 결과 가져오기\n",
    "    bm25_search_results = bm25_search(bm25_index, chunks, query, k=len(chunks))  # BM25 검색 수행 (bm25_results를 bm25_search_results로 변경)\n",
    "    \n",
    "    # 문서 인덱스를 점수에 매핑하는 딕셔너리 생성\n",
    "    vector_scores_map = {result_item[\"metadata\"][\"index\"]: result_item[\"similarity\"] for result_item in vector_search_results} # vector_scores_dict, result를 vector_scores_map, result_item으로 변경\n",
    "    bm25_scores_map = {result_item[\"metadata\"][\"index\"]: result_item[\"bm25_score\"] for result_item in bm25_search_results} # bm25_scores_dict, result를 bm25_scores_map, result_item으로 변경\n",
    "    \n",
    "    # 모든 문서에 두 가지 방법 모두에 대한 점수가 있는지 확인\n",
    "    all_document_items = vector_store.get_all_documents() # all_docs를 all_document_items로 변경\n",
    "    combined_search_results = [] # combined_results를 combined_search_results로 변경\n",
    "    \n",
    "    for i, doc_item in enumerate(all_document_items): # doc을 doc_item으로 변경\n",
    "        vector_score_val = vector_scores_map.get(i, 0.0)  # 벡터 점수 가져오기 (없으면 0) (vector_score를 vector_score_val로 변경)\n",
    "        bm25_score_val = bm25_scores_map.get(i, 0.0)  # BM25 점수 가져오기 (없으면 0) (bm25_score를 bm25_score_val로 변경)\n",
    "        combined_search_results.append({\n",
    "            \"text\": doc_item[\"text\"],\n",
    "            \"metadata\": doc_item[\"metadata\"],\n",
    "            \"vector_score\": vector_score_val,\n",
    "            \"bm25_score\": bm25_score_val,\n",
    "            \"index\": i\n",
    "        })\n",
    "    \n",
    "    # 점수를 배열로 추출\n",
    "    vector_scores_arr = np.array([doc_item[\"vector_score\"] for doc_item in combined_search_results]) # vector_scores를 vector_scores_arr로, doc을 doc_item으로 변경\n",
    "    bm25_scores_arr = np.array([doc_item[\"bm25_score\"] for doc_item in combined_search_results]) # bm25_scores를 bm25_scores_arr로, doc을 doc_item으로 변경\n",
    "    \n",
    "    # 점수 정규화 (0-1 범위로)\n",
    "    # 분모가 0이 되는 것을 방지하기 위해 작은 값(epsilon) 추가\n",
    "    norm_vector_scores_arr = (vector_scores_arr - np.min(vector_scores_arr)) / (np.max(vector_scores_arr) - np.min(vector_scores_arr) + epsilon)\n",
    "    norm_bm25_scores_arr = (bm25_scores_arr - np.min(bm25_scores_arr)) / (np.max(bm25_scores_arr) - np.min(bm25_scores_arr) + epsilon)\n",
    "    \n",
    "    # 결합된 점수 계산\n",
    "    final_combined_scores = alpha * norm_vector_scores_arr + (1 - alpha) * norm_bm25_scores_arr # combined_scores를 final_combined_scores로 변경\n",
    "    \n",
    "    # 결과에 결합된 점수 추가\n",
    "    for i, score_val in enumerate(final_combined_scores): # score를 score_val로 변경\n",
    "        combined_search_results[i][\"combined_score\"] = float(score_val)\n",
    "    \n",
    "    # 결합된 점수 기준으로 정렬 (내림차순)\n",
    "    combined_search_results.sort(key=lambda x: x[\"combined_score\"], reverse=True)\n",
    "    \n",
    "    # 상위 k개 결과 반환\n",
    "    top_fusion_results = combined_search_results[:k] # top_results를 top_fusion_results로 변경\n",
    "    \n",
    "    print(f\"퓨전 검색으로 {len(top_fusion_results)}개의 문서 검색됨\")\n",
    "    return top_fusion_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 처리 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    퓨전 검색을 위해 문서를 처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        chunk_size (int): 각 청크의 문자 크기\n",
    "        chunk_overlap (int): 청크 간 문자 중첩\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[Dict], SimpleVectorStore, BM25Okapi]: 청크, 벡터 저장소 및 BM25 인덱스\n",
    "    \"\"\"\n",
    "    # PDF 파일에서 텍스트 추출\n",
    "    raw_text = extract_text_from_pdf(pdf_path) # text를 raw_text로 변경\n",
    "    \n",
    "    # 추출된 텍스트 정리하여 추가 공백 및 특수 문자 제거\n",
    "    cleaned_text_content = clean_text(raw_text) # cleaned_text를 cleaned_text_content로 변경\n",
    "    \n",
    "    # 정리된 텍스트를 중첩되는 청크로 분할\n",
    "    document_chunks = chunk_text(cleaned_text_content, chunk_size, chunk_overlap) # chunks를 document_chunks로 변경\n",
    "    \n",
    "    # 임베딩 생성을 위해 각 청크에서 텍스트 내용 추출\n",
    "    chunk_text_contents = [chunk_item[\"text\"] for chunk_item in document_chunks] # chunk_texts를 chunk_text_contents로, chunk를 chunk_item으로 변경\n",
    "    print(\"청크에 대한 임베딩 생성 중...\")\n",
    "    \n",
    "    # 청크 텍스트에 대한 임베딩 생성\n",
    "    chunk_embeddings_list = create_embeddings(chunk_text_contents) # embeddings를 chunk_embeddings_list로 변경\n",
    "    \n",
    "    # 벡터 저장소 초기화\n",
    "    vector_store_instance = SimpleVectorStore() # vector_store를 vector_store_instance로 변경\n",
    "    \n",
    "    # 청크와 해당 임베딩을 벡터 저장소에 추가\n",
    "    vector_store_instance.add_items(document_chunks, chunk_embeddings_list)\n",
    "    print(f\"벡터 저장소에 {len(document_chunks)}개의 항목 추가됨\")\n",
    "    \n",
    "    # 청크에서 BM25 인덱스 생성\n",
    "    bm25_index_instance = create_bm25_index(document_chunks) # bm25_index를 bm25_index_instance로 변경\n",
    "    \n",
    "    # 청크, 벡터 저장소 및 BM25 인덱스 반환\n",
    "    return document_chunks, vector_store_instance, bm25_index_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 응답 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    \"\"\"\n",
    "    질의와 컨텍스트를 기반으로 응답을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        context (str): 검색된 문서의 컨텍스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 생성된 응답\n",
    "    \"\"\"\n",
    "    # AI 어시스턴트를 안내하는 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"당신은 도움이 되는 AI 어시스턴트입니다. 제공된 컨텍스트를 기반으로 사용자의 질문에 답변하십시오. \n",
    "    컨텍스트에 질문에 완전히 답변할 관련 정보가 포함되어 있지 않으면 이 한계를 인정하십시오.\"\"\"\n",
    "\n",
    "    # 컨텍스트와 질의로 사용자 프롬프트 형식 지정\n",
    "    user_prompt = f\"\"\"컨텍스트:\n",
    "    {context}\n",
    "\n",
    "    질문: {query}\n",
    "\n",
    "    제공된 컨텍스트를 기반으로 질문에 답변하십시오.\"\"\"\n",
    "\n",
    "    # OpenAI API를 사용하여 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 사용할 모델 지정\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 어시스턴트를 안내하는 시스템 메시지\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 컨텍스트와 질의가 포함된 사용자 메시지\n",
    "        ],\n",
    "        temperature=0.1  # 응답 생성 온도 설정 (낮을수록 결정적)\n",
    "    )\n",
    "    \n",
    "    # 생성된 응답 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 검색 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    퓨전 RAG를 사용하여 질의에 답변합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        chunks (List[Dict]): 텍스트 청크\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 수\n",
    "        alpha (float): 벡터 점수 가중치\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 검색된 문서와 응답을 포함하는 질의 결과\n",
    "    \"\"\"\n",
    "    # 퓨전 검색 방법을 사용하여 문서 검색\n",
    "    retrieved_docs_list = fusion_retrieval(query, chunks, vector_store, bm25_index, k=k, alpha=alpha) # retrieved_docs를 retrieved_docs_list로 변경\n",
    "    \n",
    "    # 검색된 문서의 텍스트를 구분 기호로 결합하여 컨텍스트 형식 지정\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc_item[\"text\"] for doc_item in retrieved_docs_list]) # context를 context_text로, doc을 doc_item으로 변경\n",
    "    \n",
    "    # 질의와 형식화된 컨텍스트를 기반으로 응답 생성\n",
    "    response_text = generate_response(query, context_text) # response를 response_text로 변경\n",
    "    \n",
    "    # 질의, 검색된 문서 및 생성된 응답 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs_list,\n",
    "        \"response\": response_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색 방법 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_only_rag(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    벡터 기반 RAG만 사용하여 질의에 답변합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        k (int): 검색할 문서 수\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 질의 결과\n",
    "    \"\"\"\n",
    "    # 질의 임베딩 생성\n",
    "    query_embedding_vector = create_embeddings(query) # query_embedding을 query_embedding_vector로 변경\n",
    "    \n",
    "    # 벡터 기반 유사도 검색을 사용하여 문서 검색\n",
    "    retrieved_docs_list = vector_store.similarity_search_with_scores(query_embedding_vector, k=k) # retrieved_docs를 retrieved_docs_list로 변경\n",
    "    \n",
    "    # 검색된 문서의 텍스트를 구분 기호로 결합하여 컨텍스트 형식 지정\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc_item[\"text\"] for doc_item in retrieved_docs_list]) # context를 context_text로, doc을 doc_item으로 변경\n",
    "    \n",
    "    # 질의와 형식화된 컨텍스트를 기반으로 응답 생성\n",
    "    response_text = generate_response(query, context_text) # response를 response_text로 변경\n",
    "    \n",
    "    # 질의, 검색된 문서 및 생성된 응답 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs_list,\n",
    "        \"response\": response_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_only_rag(query, chunks, bm25_index, k=5):\n",
    "    \"\"\"\n",
    "    BM25 기반 RAG만 사용하여 질의에 답변합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        chunks (List[Dict]): 텍스트 청크\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 수\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 질의 결과\n",
    "    \"\"\"\n",
    "    # BM25 검색을 사용하여 문서 검색\n",
    "    retrieved_docs_list = bm25_search(bm25_index, chunks, query, k=k) # retrieved_docs를 retrieved_docs_list로 변경\n",
    "    \n",
    "    # 검색된 문서의 텍스트를 구분 기호로 결합하여 컨텍스트 형식 지정\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc_item[\"text\"] for doc_item in retrieved_docs_list]) # context를 context_text로, doc을 doc_item으로 변경\n",
    "    \n",
    "    # 질의와 형식화된 컨텍스트를 기반으로 응답 생성\n",
    "    response_text = generate_response(query, context_text) # response를 response_text로 변경\n",
    "    \n",
    "    # 질의, 검색된 문서 및 생성된 응답 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs_list,\n",
    "        \"response\": response_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(query, chunks, vector_store, bm25_index, k=5, alpha=0.5, reference_answer=None):\n",
    "    \"\"\"\n",
    "    질의에 대한 다양한 검색 방법을 비교합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        chunks (List[Dict]): 텍스트 청크\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 수\n",
    "        alpha (float): 퓨전 검색에서 벡터 점수 가중치\n",
    "        reference_answer (str, optional): 비교를 위한 참조 답변\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 비교 결과\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== '{query}' 질의에 대한 검색 방법 비교 중 ===\\n\")\n",
    "    \n",
    "    # 벡터 전용 RAG 실행\n",
    "    print(\"\\n벡터 전용 RAG 실행 중...\")\n",
    "    vector_only_result = vector_only_rag(query, vector_store, k) # vector_result를 vector_only_result로 변경\n",
    "    \n",
    "    # BM25 전용 RAG 실행\n",
    "    print(\"\\nBM25 전용 RAG 실행 중...\")\n",
    "    bm25_only_result = bm25_only_rag(query, chunks, bm25_index, k) # bm25_result를 bm25_only_result로 변경\n",
    "    \n",
    "    # 퓨전 RAG 실행\n",
    "    print(\"\\n퓨전 RAG 실행 중...\")\n",
    "    fusion_result_data = answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k, alpha) # fusion_result를 fusion_result_data로 변경\n",
    "    \n",
    "    # 다양한 검색 방법의 응답 비교\n",
    "    print(\"\\n응답 비교 중...\")\n",
    "    comparison_analysis = evaluate_responses( # comparison을 comparison_analysis로 변경\n",
    "        query, \n",
    "        vector_only_result[\"response\"], \n",
    "        bm25_only_result[\"response\"], \n",
    "        fusion_result_data[\"response\"],\n",
    "        reference_answer\n",
    "    )\n",
    "    \n",
    "    # 비교 결과 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"vector_result\": vector_only_result,\n",
    "        \"bm25_result\": bm25_only_result,\n",
    "        \"fusion_result\": fusion_result_data,\n",
    "        \"comparison\": comparison_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_responses(query, vector_response, bm25_response, fusion_response, reference_answer=None):\n",
    "    \"\"\"\n",
    "    다양한 검색 방법의 응답을 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        vector_response (str): 벡터 전용 RAG의 응답\n",
    "        bm25_response (str): BM25 전용 RAG의 응답\n",
    "        fusion_response (str): 퓨전 RAG의 응답\n",
    "        reference_answer (str, optional): 참조 답변\n",
    "        \n",
    "    Returns:\n",
    "        str: 응답 평가\n",
    "    \"\"\"\n",
    "    # 평가자에게 평가 프로세스를 안내하는 시스템 프롬프트\n",
    "    system_prompt = \"\"\"당신은 정보 검색 시스템의 전문 평가자입니다. 세 가지 다른 검색 접근 방식의 응답을 비교하십시오:\n",
    "    1. 벡터 기반 검색: 의미론적 유사성을 사용하여 문서 검색\n",
    "    2. BM25 키워드 검색: 키워드 일치를 사용하여 문서 검색\n",
    "    3. 퓨전 검색: 벡터 및 키워드 접근 방식 모두 결합\n",
    "\n",
    "    다음을 기준으로 응답을 평가하십시오:\n",
    "    - 질의 관련성\n",
    "    - 사실적 정확성\n",
    "    - 포괄성\n",
    "    - 명확성 및 일관성\"\"\"\n",
    "\n",
    "    # 질의와 응답을 포함하는 사용자 프롬프트\n",
    "    user_prompt = f\"\"\"질의: {query}\n",
    "\n",
    "    벡터 기반 응답:\n",
    "    {vector_response}\n",
    "\n",
    "    BM25 키워드 응답:\n",
    "    {bm25_response}\n",
    "\n",
    "    퓨전 응답:\n",
    "    {fusion_response}\n",
    "    \"\"\"\n",
    "\n",
    "    # 제공된 경우 프롬프트에 참조 답변 추가\n",
    "    if reference_answer:\n",
    "        user_prompt += f\"\"\"\n",
    "            참조 답변:\n",
    "            {reference_answer}\n",
    "        \"\"\"\n",
    "\n",
    "    # 사용자 프롬프트에 자세한 비교 지침 추가\n",
    "    user_prompt += \"\"\"\n",
    "    이 세 가지 응답에 대한 자세한 비교를 제공하십시오. 이 질의에 대해 어떤 접근 방식이 가장 좋은 성과를 냈는지, 그 이유는 무엇인지 설명하십시오.\n",
    "    이 특정 질의에 대한 각 접근 방식의 강점과 약점에 대해 구체적으로 설명하십시오.\n",
    "    \"\"\"\n",
    "\n",
    "    # meta-llama/Llama-3.2-3B-Instruct를 사용하여 평가 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",  # 사용할 모델 지정\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 평가자를 안내하는 시스템 메시지\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 질의와 응답이 포함된 사용자 메시지\n",
    "        ],\n",
    "        temperature=0  # 응답 생성 온도 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 평가 내용 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 평가 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fusion_retrieval(pdf_path, test_queries, reference_answers=None, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    다른 방법과 비교하여 퓨전 검색을 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        test_queries (List[str]): 테스트 질의 목록\n",
    "        reference_answers (List[str], optional): 참조 답변\n",
    "        k (int): 검색할 문서 수\n",
    "        alpha (float): 퓨전 검색에서 벡터 점수 가중치\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 평가 결과\n",
    "    \"\"\"\n",
    "    print(\"=== 퓨전 검색 평가 ===\\n\")\n",
    "    \n",
    "    # 문서를 처리하여 텍스트 추출, 청크 생성, 벡터 및 BM25 인덱스 구축\n",
    "    document_chunks, vector_store_instance, bm25_index_instance = process_document(pdf_path) # chunks, vector_store, bm25_index 변수명 변경\n",
    "    \n",
    "    # 각 질의에 대한 결과를 저장할 리스트 초기화\n",
    "    evaluation_results_list = [] # results를 evaluation_results_list로 변경\n",
    "    \n",
    "    # 각 테스트 질의 반복\n",
    "    for i, query_text in enumerate(test_queries): # query를 query_text로 변경\n",
    "        print(f\"\\n\\n=== 질의 {i+1}/{len(test_queries)} 평가 중 ===\")\n",
    "        print(f\"질의: {query_text}\")\n",
    "        \n",
    "        # 사용 가능한 경우 참조 답변 가져오기\n",
    "        reference_text = None # reference를 reference_text로 변경\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference_text = reference_answers[i]\n",
    "        \n",
    "        # 현재 질의에 대한 검색 방법 비교\n",
    "        comparison_result = compare_retrieval_methods( # comparison을 comparison_result로 변경\n",
    "            query_text, \n",
    "            document_chunks, \n",
    "            vector_store_instance, \n",
    "            bm25_index_instance, \n",
    "            k=k, \n",
    "            alpha=alpha,\n",
    "            reference_answer=reference_text\n",
    "        )\n",
    "        \n",
    "        # 결과 리스트에 비교 결과 추가\n",
    "        evaluation_results_list.append(comparison_result)\n",
    "        \n",
    "        # 다양한 검색 방법의 응답 출력\n",
    "        print(\"\\n=== 벡터 기반 응답 ===\")\n",
    "        print(comparison_result[\"vector_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== BM25 응답 ===\")\n",
    "        print(comparison_result[\"bm25_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 퓨전 응답 ===\")\n",
    "        print(comparison_result[\"fusion_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 비교 ===\")\n",
    "        print(comparison_result[\"comparison\"])\n",
    "    \n",
    "    # 퓨전 검색 성능에 대한 전체 분석 생성\n",
    "    overall_analysis_text = generate_overall_analysis(evaluation_results_list) # overall_analysis를 overall_analysis_text로 변경\n",
    "    \n",
    "    # 결과와 전체 분석 반환\n",
    "    return {\n",
    "        \"results\": evaluation_results_list,\n",
    "        \"overall_analysis\": overall_analysis_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overall_analysis(results):\n",
    "    \"\"\"\n",
    "    퓨전 검색에 대한 전체 분석을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        results (List[Dict]): 질의 평가 결과\n",
    "        \n",
    "    Returns:\n",
    "        str: 전체 분석\n",
    "    \"\"\"\n",
    "    # 평가 프로세스를 안내하는 시스템 프롬프트\n",
    "    system_prompt = \"\"\"당신은 정보 검색 시스템의 전문 평가자입니다. \n",
    "    여러 테스트 질의를 기반으로 세 가지 검색 접근 방식을 비교하는 전체 분석을 제공하십시오:\n",
    "    1. 벡터 기반 검색 (의미론적 유사성)\n",
    "    2. BM25 키워드 검색 (키워드 일치)\n",
    "    3. 퓨전 검색 (두 가지 모두 결합)\n",
    "\n",
    "    다음에 초점을 맞추십시오:\n",
    "    1. 각 접근 방식이 가장 좋은 성능을 보이는 질의 유형\n",
    "    2. 각 접근 방식의 전반적인 강점과 약점\n",
    "    3. 퓨전 검색이 절충안을 어떻게 균형 잡는지\n",
    "    4. 각 접근 방식을 언제 사용해야 하는지에 대한 권장 사항\"\"\"\n",
    "\n",
    "    # 각 질의에 대한 평가 요약 생성\n",
    "    evaluations_summary_text = \"\" # evaluations_summary를 evaluations_summary_text로 변경\n",
    "    for i, result_item in enumerate(results): # result를 result_item으로 변경\n",
    "        evaluations_summary_text += f\"질의 {i+1}: {result_item['query']}\\n\"\n",
    "        evaluations_summary_text += f\"비교 요약: {result_item['comparison'][:200]}...\\n\\n\" # 너무 길 경우를 대비해 요약본 사용\n",
    "\n",
    "    # 평가 요약을 포함하는 사용자 프롬프트\n",
    "    user_prompt = f\"\"\"다음 {len(results)}개 질의에 대한 다양한 검색 방법 평가를 바탕으로, \n",
    "    이 세 가지 접근 방식을 비교하는 전체 분석을 제공하십시오:\n",
    "\n",
    "{evaluations_summary_text}\n",
    "\n",
    "벡터 기반, BM25 및 퓨전 검색 접근 방식의 상대적인 강점과 약점에 대한 포괄적인 분석을 제공하고,\n",
    "퓨전 검색이 개별 방법에 비해 언제, 왜 이점을 제공하는지 강조하십시오.\"\"\"\n",
    "\n",
    "    # meta-llama/Llama-3.2-3B-Instruct를 사용하여 전체 분석 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0 # 일관된 분석을 위해 온도 0 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 분석 내용 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퓨전 검색 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 퓨전 검색 평가 ===\n",
      "\n",
      "data/AI_Information.pdf에서 텍스트 추출 중...\n",
      "생성된 텍스트 청크 수: 42\n",
      "청크에 대한 임베딩 생성 중...\n",
      "벡터 저장소에 42개의 항목 추가됨\n",
      "42개의 문서로 BM25 인덱스 생성됨\n",
      "\n",
      "\n",
      "=== 질의 1/1 평가 중 ===\n",
      "질의: 자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?\n",
      "\n",
      "=== '자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?' 질의에 대한 검색 방법 비교 중 ===\n",
      "\n",
      "\n",
      "벡터 전용 RAG 실행 중...\n",
      "\n",
      "BM25 전용 RAG 실행 중...\n",
      "\n",
      "퓨전 RAG 실행 중...\n",
      "'자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?' 질의에 대한 퓨전 검색 수행 중...\n",
      "퓨전 검색으로 5개의 문서 검색됨\n",
      "\n",
      "응답 비교 중...\n",
      "\n",
      "=== 벡터 기반 응답 ===\n",
      "제공된 컨텍스트는 트랜스포머 모델을 구체적으로 언급하지 않습니다. 그러나 자연어 처리(NLP)는 컴퓨터가 인간 언어를 이해, 해석 및 생성할 수 있도록 하는 AI의 한 분야라고 언급합니다. NLP 기술은 챗봇, 기계 번역, 텍스트 요약 및 감성 분석에 사용됩니다.\n",
      "\n",
      "트랜스포머 모델은 기계 번역, 텍스트 생성 및 텍스트 분류와 같은 NLP 작업에 특히 효과적인 신경망 아키텍처 유형입니다. 제공된 컨텍스트에는 명시적으로 언급되어 있지 않습니다.\n",
      "\n",
      "트랜스포머 모델에 대한 정보를 찾고 있다면 이 주제에 대한 일반적인 정보를 제공할 수 있습니다. 그러나 제공된 컨텍스트는 트랜스포머 모델을 구체적으로 다루지 않는다는 점에 유의하십시오.\n",
      "\n",
      "=== BM25 응답 ===\n",
      "제공된 컨텍스트는 트랜스포머 모델이나 자연어 처리에서의 적용에 대해 언급하지 않습니다. 컨텍스트는 딥 러닝, 컨볼루션 신경망, 순환 신경망, 자연어 처리 및 기계 학습과 같은 다양한 주제를 다루지만 트랜스포머 모델에 대해서는 구체적으로 논의하지 않습니다.\n",
      "\n",
      "트랜스포머 모델에 대한 정보를 찾고 있다면 이 주제에 대한 일반적인 정보를 제공할 수 있습니다. 트랜스포머 모델은 기계 번역, 텍스트 생성 및 언어 이해와 같은 자연어 처리 작업에서 인기를 얻은 신경망 아키텍처 유형입니다. 순차적 데이터의 장거리 의존성을 처리하는 데 특히 효과적이며 많은 NLP 응용 프로그램에서 널리 채택되었습니다. 그러나 이 정보는 제공된 컨텍스트에 없습니다.\n",
      "\n",
      "=== 퓨전 응답 ===\n",
      "제공된 컨텍스트는 자연어 처리에서 트랜스포머 모델의 주요 적용 분야를 명시적으로 언급하지 않습니다. 그러나 생성적 적대 신경망(GAN)과 트랜스포머는 이미지, 텍스트 및 음악을 포함한 원본 콘텐츠를 만들 수 있는 생성 AI 모델의 예라고 언급합니다.\n",
      "\n",
      "일반적인 지식을 바탕으로 트랜스포머 모델은 다음과 같은 작업에 자연어 처리(NLP)에서 널리 사용됩니다.\n",
      "\n",
      "1. 기계 번역\n",
      "2. 텍스트 생성\n",
      "3. 감성 분석\n",
      "4. 텍스트 분류\n",
      "5. 언어 모델링\n",
      "\n",
      "이러한 모델은 많은 NLP 작업에서 최첨단 결과를 달성했으며 많은 응용 프로그램에서 인기 있는 선택이 되었습니다.\n",
      "\n",
      "NLP에서 트랜스포머 모델의 적용에 대한 더 구체적인 정보를 찾고 있다면 더 일반적인 정보를 제공하거나 더 많은 리소스를 안내해 드릴 수 있습니다.\n",
      "\n",
      "=== 비교 ===\n",
      "**벡터 기반, BM25 키워드 및 퓨전 검색 접근 방식 비교**\n",
      "\n",
      "주어진 질의 \"자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?\"에 대해 관련성, 사실적 정확성, 포괄성 및 명확성/일관성을 기준으로 응답을 평가할 수 있습니다.\n",
      "\n",
      "**관련성:**\n",
      "\n",
      "* 벡터 기반 응답: 6/10 (응답은 질의와 관련이 있지만 직접적으로 답변하지는 않습니다. NLP에 대한 일반적인 정보를 제공하고 트랜스포머 모델을 언급하지만 주요 적용 분야를 명시적으로 언급하지는 않습니다.)\n",
      "* BM25 키워드 응답: 5/10 (응답은 NLP에서 트랜스포머 모델이나 그 적용 분야를 언급하지 않으므로 질의와 직접적으로 관련이 없습니다.)\n",
      "* 퓨전 응답: 9/10 (응답은 질의에 직접 답변하고 NLP에서 트랜스포머 모델의 주요 적용 분야에 대한 포괄적인 목록을 제공합니다.)\n",
      "\n",
      "**사실적 정확성:**\n",
      "\n",
      "* 벡터 기반 응답: 8/10 (응답은 일반적으로 정확하지만 NLP에서 트랜스포머 모델의 주요 적용 분야를 명시적으로 언급하지는 않습니다.)\n",
      "* BM25 키워드 응답: 8/10 (응답은 일반적으로 정확하지만 NLP에서 트랜스포머 모델이나 그 적용 분야를 언급하지는 않습니다.)\n",
      "* 퓨전 응답: 9/10 (응답은 사실적으로 정확하며 NLP에서 트랜스포머 모델의 주요 적용 분야에 대한 포괄적인 목록을 제공합니다.)\n",
      "\n",
      "**포괄성:**\n",
      "\n",
      "* 벡터 기반 응답: 6/10 (응답은 NLP에 대한 일반적인 정보를 제공하지만 트랜스포머 모델의 주요 적용 분야를 명시적으로 언급하지는 않습니다.)\n",
      "* BM25 키워드 응답: 4/10 (응답은 NLP에서 트랜스포머 모델이나 그 적용 분야에 대한 정보를 제공하지 않습니다.)\n",
      "* 퓨전 응답: 9/10 (응답은 NLP에서 트랜스포머 모델의 주요 적용 분야에 대한 포괄적인 목록을 제공합니다.)\n",
      "\n",
      "**명확성 및 일관성:**\n",
      "\n",
      "* 벡터 기반 응답: 7/10 (응답은 명확하지만 트랜스포머 모델의 주요 적용 분야를 명시적으로 언급하지는 않습니다.)\n",
      "* BM25 키워드 응답: 6/10 (응답은 명확하지만 NLP에서 트랜스포머 모델이나 그 적용 분야를 언급하지는 않습니다.)\n",
      "* 퓨전 응답: 9/10 (응답은 명확하고 간결하며 잘 구성되어 NLP에서 트랜스포머 모델의 주요 적용 분야를 쉽게 이해할 수 있습니다.)\n",
      "\n",
      "**전반적인 성능:**\n",
      "\n",
      "* 벡터 기반 응답: 6.5/10\n",
      "* BM25 키워드 응답: 5.5/10\n",
      "* 퓨전 응답: 8.5/10\n",
      "\n",
      "평가를 바탕으로 이 질의에 대해서는 퓨전 검색 접근 방식이 가장 좋은 성능을 보였습니다. 퓨전 응답은 NLP에서 트랜스포머 모델의 주요 적용 분야에 대한 포괄적인 목록을 제공했으며, 사실적으로 정확하고 명확하며 간결했습니다. 벡터 기반 응답은 관련성이 있었지만 트랜스포머 모델의 주요 적용 분야를 명시적으로 언급하지 않았으며, BM25 키워드 응답은 질의와 직접적으로 관련이 없었습니다.\n",
      "\n",
      "\n",
      "=== 전체 분석 ===\n",
      "\n",
      "**전체 분석: 벡터 기반, BM25 및 퓨전 검색 접근 방식**\n",
      "\n",
      "이 분석에서는 세 가지 검색 접근 방식, 즉 벡터 기반, BM25 키워드 및 퓨전 검색의 성능을 평가합니다. 각 접근 방식의 강점과 약점, 특정 질의 유형에서의 성능, 그리고 퓨전 검색이 절충안을 어떻게 균형 잡는지 살펴봅니다.\n",
      "\n",
      "**질의 1: 자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?**\n",
      "\n",
      "이 질의에 대해 세 가지 접근 방식의 성능은 다음과 같이 평가할 수 있습니다.\n",
      "\n",
      "1. **벡터 기반 검색 (의미론적 유사성)**: 이 접근 방식은 질의와 문서의 의미론적 의미를 이해해야 하는 질의에 적합합니다. 이 경우 질의는 트랜스포머 모델의 주요 적용 분야에 대해 묻고 있으므로 의미론적 이해가 필요합니다. 벡터 기반 접근 방식은 질의와 문서의 미묘한 차이를 포착할 수 있으므로 좋은 성능을 보일 가능성이 높습니다.\n",
      "\n",
      "성능: 8/10\n",
      "\n",
      "2. **BM25 키워드 검색 (키워드 일치)**: 이 접근 방식은 정확한 키워드 일치가 필요한 질의에 적합합니다. 이 경우 질의는 트랜스포머 모델의 주요 적용 분야에 대해 묻고 있으므로 정확한 키워드 일치가 필요합니다. 그러나 질의는 또한 주요 적용 분야에 대해 묻고 있으므로 문서에 대한 더 미묘한 이해가 필요할 수 있습니다.\n",
      "\n",
      "성능: 6/10\n",
      "\n",
      "3. **퓨전 검색 (두 가지 모두 결합)**: 이 접근 방식은 벡터 기반 검색과 BM25 키워드 검색의 장점을 모두 결합합니다. 두 가지 접근 방식을 모두 사용하여 퓨전 검색은 질의의 의미론적 의미와 정확한 키워드 일치를 모두 포착할 수 있습니다.\n",
      "\n",
      "성능: 9/10\n",
      "\n",
      "**각 접근 방식의 전반적인 강점과 약점**\n",
      "\n",
      "1. **벡터 기반 검색 (의미론적 유사성)**:\n",
      "\t* 강점: 질의와 문서의 미묘한 차이를 포착할 수 있으며, 의미론적 이해가 필요한 질의에 적합합니다.\n",
      "\t* 약점: 정확한 키워드 일치가 필요한 질의에는 성능이 좋지 않을 수 있습니다.\n",
      "2. **BM25 키워드 검색 (키워드 일치)**:\n",
      "\t* 강점: 정확한 키워드 일치가 필요한 질의에 좋은 성능을 보일 수 있습니다.\n",
      "\t* 약점: 질의와 문서의 미묘한 차이를 포착하지 못할 수 있으며, 의미론적 이해가 필요한 질의에는 적합하지 않습니다.\n",
      "3. **퓨전 검색 (두 가지 모두 결합)**:\n",
      "\t* 강점: 질의의 의미론적 의미와 정확한 키워드 일치를 모두 포착할 수 있으며, 광범위한 질의에 적합합니다.\n",
      "\t* 약점: 더 많은 계산 리소스와 복잡한 구현이 필요할 수 있습니다.\n",
      "\n",
      "**퓨전 검색이 절충안을 어떻게 균형 잡는지**\n",
      "\n",
      "퓨전 검색은 벡터 기반 검색과 BM25 키워드 검색의 장점을 모두 결합하여 두 접근 방식 간의 절충안을 균형 잡습니다. 두 가지를 모두 사용하여 퓨전 검색은 질의의 의미론적 의미와 정확한 키워드 일치를 모두 포착하여 보다 포괄적인 검색 결과를 얻을 수 있습니다.\n",
      "\n",
      "**각 접근 방식을 언제 사용해야 하는지에 대한 권장 사항**\n",
      "\n",
      "1. **벡터 기반 검색 (의미론적 유사성)**: 용어의 의미나 문맥에 대해 묻는 질문과 같이 의미론적 이해가 필요한 질의에 사용합니다.\n",
      "2. **BM25 키워드 검색 (키워드 일치)**: 특정 용어나 구문에 대한 검색과 같이 정확한 키워드 일치가 필요한 질의에 사용합니다.\n",
      "3. **퓨전 검색 (두 가지 모두 결합)**: 미묘한 의미를 가진 용어나 구문에 대한 검색과 같이 의미론적 이해와 정확한 키워드 일치 간의 균형이 필요한 질의에 사용합니다.\n",
      "\n",
      "결론적으로 퓨전 검색은 벡터 기반 검색과 BM25 키워드 검색의 장점을 모두 결합하여 개별 방법보다 이점을 제공합니다. 두 가지 접근 방식을 모두 사용하여 퓨전 검색은 질의의 의미론적 의미와 정확한 키워드 일치를 모두 포착하여 보다 포괄적인 검색 결과를 얻을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# PDF 문서 경로\n",
    "# 지식 검색 테스트를 위한 AI 정보가 포함된 PDF 문서 경로\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# 단일 AI 관련 테스트 질의 정의\n",
    "test_queries = [\n",
    "    \"자연어 처리에서 트랜스포머 모델의 주요 적용 분야는 무엇입니까?\"  # AI 관련 특정 질의\n",
    "]\n",
    "\n",
    "# 선택적 참조 답변\n",
    "reference_answers = [\n",
    "    \"트랜스포머 모델은 기계 번역, 텍스트 요약, 질의응답, 감성 분석 및 텍스트 생성을 포함한 자연어 처리 응용 분야에 혁명을 일으켰습니다. 텍스트의 장거리 의존성을 포착하는 데 뛰어나며 BERT, GPT 및 T5와 같은 모델의 기반이 되었습니다.\",\n",
    "]\n",
    "\n",
    "# 매개변수 설정\n",
    "k = 5  # 검색할 문서 수\n",
    "alpha = 0.5  # 벡터 점수 가중치 (0.5는 벡터와 BM25 간의 동일한 가중치를 의미)\n",
    "\n",
    "# 평가 실행\n",
    "evaluation_results = evaluate_fusion_retrieval(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers,\n",
    "    k=k,\n",
    "    alpha=alpha\n",
    ")\n",
    "\n",
    "# 전체 분석 출력\n",
    "print(\"\\n\\n=== 전체 분석 ===\")\n",
    "print(evaluation_results[\"overall_analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-new-specific-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

[end of 16_fusion_rag.ipynb]
